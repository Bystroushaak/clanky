<!DOCTYPE html>
<html>
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.6.0">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>Jak na vlastnÃ­ LLM (GPT)</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css">
  <link rel="alternate" type="application/atom+xml" href="https://blog.rfox.eu/atom_cz.xml">
  <link rel="shortcut icon" href="/favicon.ico">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Bystroushaak">
  <meta name="twitter:creator" content="@Bystroushaak">
  <meta name="twitter:title" content="Jak na vlastnÃ­ LLM (GPT)">
  <meta name="twitter:description" content="PovÃ­dÃ¡nÃ­ o GPT a LLM (Large Language Models), nÃ¡vod jak si rozjet menÅ¡Ã­ modely doma a pÃ¡r ukÃ¡zek jak pouÅ¾Ã­vÃ¡m GPT4.">
  <meta name="twitter:image" content="https://blog.rfox.eu/cz/Programovani/Jak_na_vlastni_LLM_GPT/twitter_preview.jpg">
  <script src="../../../scripts.js"></script>
  <meta name="description" content="PovÃ­dÃ¡nÃ­ o GPT a LLM (Large Language Models), nÃ¡vod jak si rozjet menÅ¡Ã­ modely doma a pÃ¡r ukÃ¡zek jak pouÅ¾Ã­vÃ¡m GPT4.">
  <meta name="keywords" content="ai,gpt,dao,m0wFG3PRCoJVTs7JcgBwsOXb3U7yPxBB"><!-- Global site tag (gtag.js) - Google Analytics -->

  <script src="https://www.googletagmanager.com/gtag/js?id=UA-142545439-1"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'UA-142545439-1');
  </script>
</head>
<body onload="on_body_load();">
  <div id="sidebar_top">
    <div>
      <a href="https://blog.rfox.eu/atom_cz.xml"><img src="../../../rss_icon.png" style="width: 3em;"></a>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;<a href="https://twitter.com/Bystroushaak"><img src="../../../twitter_icon.png" style="width: 3em;"></a>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;<a href="https://www.patreon.com/bePatron?u=2618881"><img src="../../../patreon.png" style="width: 3em;"></a>
    </div>
    <h3>New posts</h3>
    <div id="last_five_top">
      <ul>
        <li>
          <a href="../Jak_na_vlastni_LLM_GPT.html" title="Jak na vlastnÃ­ LLM (GPT)">Jak na vlastnÃ­ LLM (GPT)</a>
        </li>
        <li>
          <a href="../../Povidky/Software.html" title="Software">Software</a>
        </li>
        <li>
          <a href="../../Ostatni/Paromobilita_je_budoucnost.html" title="Paromobilita je budoucnost">Paromobilita je budoucnost</a>
        </li>
        <li>
          <a href="../../Ostatni/Algoritmus_hledani_programatorske_prace_2021-4.html" title="Algoritmus hledÃ¡nÃ­ programÃ¡torskÃ© prÃ¡ce 2021/4">Algoritmus hledÃ¡nÃ­ programÃ¡torskÃ© prÃ¡ce 2021/4</a>
        </li>
        <li>
          <a href="../../3D_tisk/Nastaveni_Blenderu_pro_3D_tisk.html" title="NastavenÃ­ Blenderu pro 3D tisk">NastavenÃ­ Blenderu pro 3D tisk</a>
        </li>
        <li>
          <a href="../../3D_modelovani/Geometricky_stred_Prahy.html" title="GeometrickÃ½ stÅ™ed Prahy">GeometrickÃ½ stÅ™ed Prahy</a>
        </li>
        <li>
          <a href="../../../Utrzky/Posta_poezie.html" title="PoÅ¡ta (poezie)">PoÅ¡ta (poezie)</a>
        </li>
        <li>
          <a href="../../Ostatni/Statni_zklamani.html" title="StÃ¡tnÃ­ zklamÃ¡nÃ­">StÃ¡tnÃ­ zklamÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../3D_tisk/3D_TODO_list_1_Drzak_na_sluchatka.html" title="3D TODO list 1; DrÅ¾Ã¡k na sluchÃ¡tka">3D TODO list 1; DrÅ¾Ã¡k na sluchÃ¡tka</a>
        </li>
        <li>
          <a href="../../Ostatni/Dva_podvodnici.html" title="Dva podvodnÃ­ci">Dva podvodnÃ­ci</a>
        </li>
      </ul>
    </div>& <a href="../../../Zmeny.html" title="ZmÄ›ny">more</a>
    <div>
      <h3>Tagy</h3>
      <p><a href="../../../Tagy/ai.html" title="ai">ai</a>, <a href="../../../Tagy/dao.html" title="dao">dao</a>, <a href="../../../Tagy/gpt.html" title="gpt">gpt</a></p>
    </div>
    <div>
      <h3>Blog categories</h3>
      <ul class="no_icon">
        <li>
          <a href="../../3D_modelovani.html" title="3D modelovÃ¡nÃ­">ğŸ“‚ 3D modelovÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../3D_tisk.html" title="3D tisk">ğŸ“‚ 3D tisk</a>
        </li>
        <li>
          <a href="../../Abclinuxu.html" title="Abclinuxu">ğŸ“‚ Abclinuxu</a>
        </li>
        <li>
          <a href="../../Crypto.html" title="Crypto">ğŸ“‚ Crypto</a>
        </li>
        <li>
          <a href="../../Hardware.html" title="Hardware">ğŸ“‚ Hardware</a>
        </li>
        <li>
          <a href="../../Hrbitov.html" title="HÅ™bitov">ğŸ“‚ HÅ™bitov</a>
        </li>
        <li>
          <a href="../../Knihy.html" title="Knihy">ğŸ“‚ Knihy</a>
        </li>
        <li>
          <a href="../../Ostatni.html" title="OstatnÃ­">ğŸ“‚ OstatnÃ­</a>
        </li>
        <li>
          <a href="../../Povidky.html" title="PovÃ­dky">ğŸ“‚ PovÃ­dky</a>
        </li>
        <li>
          <a href="../../Predstaveni.html" title="PÅ™edstavenÃ­">ğŸ“‚ PÅ™edstavenÃ­</a>
        </li>
        <li>
          <a href="../../Programovani.html" title="ProgramovÃ¡nÃ­">ğŸ“‚ ProgramovÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../index.html" title="Czech section">ğŸ“‚ Czech section</a>
        </li>
      </ul>
    </div>
  </div><a href="../../../index.html" class="breadcrumb" title="Bystroushaak's blog">Bystroushaak's blog</a> / <a href="../../index.html" class="breadcrumb" title="Czech section">Czech section</a> / <a href="../index.html" class="breadcrumb" title="ProgramovÃ¡nÃ­">ProgramovÃ¡nÃ­</a> / Jak na vlastnÃ­ LLM (GPT)
  <article id="f573db6f-7721-4fb1-98b2-a27736780416" class="page sans">
    <header>
      <h1 class="page-title">Jak na vlastnÃ­ LLM (GPT)</h1>
    </header>
    <div class="page-body">
      <p id="c861c231-f560-4583-988e-c158833bd9a5" class=""><time>@2023/04/13</time></p>
      <blockquote id="ccb23b9a-322d-4f5d-b4f8-646887e7b52b" class="">
        PÅ™edstavte si, Å¾e jste stroj.
        <p id="8bf0fe32-cbd1-46cb-b3f5-e7a59949313f" class="">JasnÄ›, jÃ¡ vÃ­m. Ale pÅ™edstavte si, Å¾e jste <em>jinÃ½ druh stroje</em>, postavenÃ½ z kovu a plastu a navrÅ¾enÃ½ ne slepÃ½m, nÃ¡hodnÃ½m pÅ™irozenÃ½m vÃ½bÄ›rem, ale inÅ¾enÃ½ry a astrofyziky, kteÅ™Ã­ majÃ­ oÄi pevnÄ› upÅ™enÃ© na konkrÃ©tnÃ­ cÃ­le. PÅ™edstavte si, Å¾e vaÅ¡Ã­m ÃºÄelem nenÃ­ rozmnoÅ¾ovat se, nebo dokonce pÅ™eÅ¾Ã­t, ale shromaÅ¾Äovat informace.</p>
        <p id="cc2e4272-74d1-48b6-bf4e-bbf082c5698f" class="">â€” <a href="https://www.databazeknih.cz/knihy/slepozrakost-77865">Slepozrakost</a>, Peter Watts</p>
      </blockquote>
      <hr id="4cacd4e0-1bec-479a-82b3-69cf7eb75b38">
      <p id="cc73e3eb-1d7d-4eaf-afb3-157251fa7af9" class="">Celebrity technickÃ©ho svÄ›ta se <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">bouÅ™Ã­</a>, Å¾e by to chtÄ›lo pozastavit vÃ½voj na poli velkÃ½ch jazykovÃ½ch modelÅ¯ na alespoÅˆ 6 mÄ›sÃ­cÅ¯.</p>
      <ul id="18fbdcf7-39f4-4058-a696-5577797df271" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://www.seznamzpravy.cz/clanek/tech-technologie-zastavte-vyvoj-umele-inteligence-volaji-odbornici-a-musk-lidstvo-to-nestiha-228605">NalÃ©havÃ¡ vÃ½zva hvÄ›zd IT: Zastavte vÃ½voj umÄ›lÃ© inteligence, jde moc rychle</a>
        </li>
      </ul>
      <ul id="6328fd76-8f3e-4b03-aa1e-aace444f66b3" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://denikn.cz/minuta/1113210/">Musk podepsal otevÅ™enÃ½ dopis pro zastavenÃ­ vÃ½voje umÄ›lÃ© inteligence</a>
        </li>
      </ul>
      <ul id="7d799613-5788-44d2-9e27-f088571f9e11" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://www.idnes.cz/technet/software/musk-ai-umela-inteligence.A230329_095318_software_alv">Musk a odbornÃ­ci Å¾Ã¡dajÃ­ pozastavenÃ­ vÃ½voje umÄ›lÃ© inteligence, bojÃ­ se rizik</a>
        </li>
      </ul>
      <p id="289607a1-b12e-4a56-8921-a3c1b174b727" class="">Jako sprÃ¡vnÃ­ chatiÄtÃ­ neutrÃ¡lovÃ© si tedy rozjedem vlastnÃ­ AI doma. Ale s pÅ™edmluvou a nÄ›jakÃ½m tÃ­m kontextem, aÅ¥ vlastnÄ› vÃ­me co dÄ›lÃ¡me.</p>
      <h1 id="fb718140-ca18-41d9-b398-2b71e3bfe179" class="">Jak chÃ¡pat GPT / LLM</h1>
      <p id="1eb46c8a-c6e9-4a40-994f-556f5405ab2c" class="">SetkÃ¡vÃ¡m se s jednÃ­m zÃ¡sadnÃ­m nepochopenÃ­m, kterÃ© Äasto majÃ­ lidi co trochu tuÅ¡Ã­ jak to funguje;</p>
      <blockquote id="a1100d50-461b-49fa-b598-1654fb3ff120" class="">
        Je to jen doplÅˆovaÄ dalÅ¡Ã­ho slova (tokenu).
      </blockquote>
      <p id="9a3742c6-031a-4efb-b58a-f4c13a7d7e1a" class="">CoÅ¾ jako jo, ale technicky vzato kdyÅ¾ pÃ­Å¡ete na klÃ¡vesnici, tak jste taky jen doplÅˆovaÄe dalÅ¡Ã­ho slova.</p>
      <figure id="0750013c-42ee-4b25-aa35-034cd642f0ba" class="image">
        <a href="Untitled.png" title="Untitled.png"><img style="width:576px" src="Untitled.png"></a>
        <figcaption>
          <em>(Zdroj:</em> <em><a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">What Is ChatGPT Doing â€¦ and Why Does It Work?</a></em><em>)</em>
        </figcaption>
      </figure>
      <p id="0fbe2853-b27a-4285-9adf-6c5be94b4011" class="">Jak vysvÄ›tluje tÅ™eba Ilya Sutskever (jeden z tvÅ¯rcÅ¯):</p>
      <figure id="8f913aae-cb77-4292-b2f4-11c3d906c4b8">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/Yf1o0TQzry8?start=394" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <p id="5c01da96-67e1-4a29-9edd-585a2490b23a" class="">K tomu aby neuronovÃ¡ sÃ­Å¥ mohla predikovat dalÅ¡Ã­ token nad gigantickÃ½m datasetem, jÃ­mÅ¾ byla trÃ©novÃ¡na, si musÃ­ vytvoÅ™it bohatÃ© vnitÅ™nÃ­ reprezentace. Ty zahrnujÃ­ nejen vÅ¡echny moÅ¾nÃ© lidskÃ© jazyky, ale i znalosti, vztahy a vzory.</p>
      <p id="703cd2a2-7a90-4652-8d21-a7396d55b92e" class="">Tohle se nÄ›kdy oznaÄuje jako <em>â€œkompreseâ€</em>, protoÅ¾e sÃ­Å¥ je, zpÅ¯sobem jakÃ½m je trÃ©novÃ¡na na velkÃ©m mnoÅ¾stvÃ­ dat, nucena vytvoÅ™it tyto reprezentace nad omezenÃ½m setem vah a neuronÅ¯. Mohla by teoreticky uklÃ¡dat miliardy ukÃ¡zek stylem ÄÃ­nskÃ©ho pokoje, kde si prostÄ› uloÅ¾Ã­ <em>â€œotÃ¡zkaâ€</em> - <em>â€œodpovÄ›Äâ€</em> (poÄÃ¡tek doplÅˆovanÃ©ho textu - nÃ¡sledujÃ­cÃ­ token). Ale tÃ­m jak je nucena operovat s omezenÃ½m mnoÅ¾stvÃ­m dostupnÃ© vnitÅ™nÃ­ pamÄ›ti jÃ­ nezbÃ½vÃ¡ nic jinÃ©ho, neÅ¾ pochopit stÃ¡le abstraktnÄ›jÅ¡Ã­ vzory. NÄ›jakÃ½m zpÅ¯sobem si to vnitÅ™nÄ› reprezentovat jako <em>â€œznalostiâ€</em> a <em>â€œchÃ¡pÃ¡nÃ­â€</em>.</p>
      <figure id="0383fefa-9488-4465-b248-c92a492d1930" class="image">
        <a href="Untitled_1.png" title="Untitled_1.png"><img style="width:949px" src="Untitled_1.png"></a>
        <figcaption>
          <em>(PlantUML vygeneroval GPT4, obrÃ¡zek vpravo</em> <em><strong>DALLÂ·E 2</strong></em><em>)</em>
        </figcaption>
      </figure>
      <p id="43614f15-9eb3-4928-8e6e-3512cca9ac16" class="">Tohle rozpoznÃ¡vÃ¡nÃ­ vzorÅ¯ se dÄ›je jak na Ãºrovni jazyka (syntaxe a gramatika), tak na Ãºrovni <em>word embeddings</em> (vÃ½znam slov, jak spolu souvisÃ­), tak na mnohem abstraktnÄ›jÅ¡Ã­ Ãºrovni (jak fungujÃ­ vÄ›ci o kterÃ½ch je Å™eÄ a jak spolu souvisÃ­).</p>
      <p id="718690d3-a807-4b51-b7d0-4583c6041938" class="">Nefunguje to tedy tak, Å¾e to doplÅˆuje konverzace doslovnÄ› na zÃ¡kladÄ› toho co uÅ¾ to nÄ›kde vidÄ›lo. Proto jsou tyto modely schopnÃ© napÅ™Ã­klad pÅ™eklÃ¡dat mezi jazyky lÃ­p neÅ¾ vÅ¡echno co dosud existovalo - protoÅ¾e opravdu rozumÃ­ kontextu toho o Äem je Å™eÄ.</p>
      <p id="f7b30599-2e74-49ce-b420-afe3bb7ac583" class="">Pokud by model jen doplÅˆoval na zÃ¡kladÄ› toho co uÅ¾ nÄ›kde vidÄ›l, tak by pÅ™eklÃ¡dat schopnÃ½ nebyl, pokud by pÅ™edtÃ­m danou vÄ›tu, nebo ideÃ¡lnÄ› celÃ½ odstavec uÅ¾ nÄ›kde nevidÄ›l.</p>
      <p id="b40ea546-992e-4b24-b18a-892fc7d427b8" class="">Jak <a href="https://www.youtube.com/watch?v=goOa0biX6Tc">Å™Ã­kÃ¡</a> Ilya Sutskever, pÅ™edstavte si, Å¾e pÅ™i trÃ©novÃ¡nÃ­ doplÅˆuje tÅ™eba text detektivky, kde vrah je oznÃ¡men aÅ¾ na poslednÃ­ strÃ¡nce knihy plnÃ© rÅ¯znÃ©ho vyÅ¡etÅ™ovÃ¡nÃ­. Aby byla sÃ­Å¥ schopna korektnÄ› doplnit jmÃ©no vraha kdyÅ¾ ho v textu detektiv vyslovÃ­, musÃ­ <em>chÃ¡pat</em> vÅ¡echny moÅ¾nÃ© souvislosti, celÃ© vyÅ¡etÅ™ovÃ¡nÃ­, rÅ¯znÃ© dÅ¯kazy a tak podobnÄ›.</p>
      <h2 id="9c007c0a-d969-4884-8303-894c58e2eb2e" class="">SimulÃ¡tory</h2>
      <p id="ae7dc46c-480d-4e47-bc69-73f813ff186b" class="">PÅ™edtÃ­m neÅ¾ pÅ™iÅ¡el chat mode byly vÃ½sledky, napÅ™Ã­klad u GPT3, pomÄ›rnÄ› nevalnÃ©. JasnÄ›, nÄ›co to dÄ›lalo, ale ÄlovÄ›k se z toho po poÄÃ¡teÄnÃ­m pÅ™ekvapenÃ­ ÃºplnÄ› neposadil na zadek, a dost Äasto se to vydalo ÃºplnÄ› jinÃ½m smÄ›rem, neÅ¾ bych chtÄ›l. CelkovÄ› to pÅ¯sobilo dost omezenÄ›.</p>
      <p id="f5be9ebd-b1f9-4b42-86b5-c8c1b2c893c8" class="">Jak uÅ¾ pozorovalo mnoho lidÃ­, dramaticky zÃ¡leÅ¾elo na promptu kterÃ½ byl AI zadÃ¡n. NÄ›kdy neumÄ›la vysvÄ›tlit nebo udÄ›lat nic. Jindy to zvlÃ¡dla, kdyÅ¾ se jÃ­ Å™eklo aÅ¥ pÅ™edstÃ­rÃ¡ Å¾e je Sherlock Holmes.</p>
      <p id="2924d1cf-19b6-4a60-9444-929bc1d359cf" class="">Za tohle mÅ¯Å¾e v podstatÄ› zpÅ¯sob jakÃ½m byla trÃ©novÃ¡na a Å¾e je to doplÅˆovaÄ textu. MÃ¡ prostÄ› tendence doplÅˆovat. K tomu aby doplÅˆovala chytÅ™e a uÅ¾iteÄnÄ› je v podstatÄ› tÅ™eba nastavit kontext tak, Å¾e <em>doplÅˆuje</em> pÅ™Ã­bÄ›h o chytrÃ© a uÅ¾iteÄnÃ© postavÄ› - tÅ™eba Sherlocku Holmesovi. Tak jak by to bylo v trÃ©novacÃ­ch datech. ChytrÃ© chovÃ¡nÃ­ v pÅ™Ã­bÄ›zÃ­ch o chytrÃ½ch lidech. Pokud ÄlovÄ›k nechal doplnit nÄ›co bez patÅ™iÄnÃ©ho kontextu, tak vÃ½sledky byly dost nÃ¡hodnÃ©.</p>
      <p id="398af488-86d8-4cfd-868c-2ccbc92c5475" class=""><a href="https://astralcodexten.substack.com/p/janus-simulators">Janus' Simulators</a> je krÃ¡snÃ½ blog na tohle tÃ©ma, se spoustou ukÃ¡zek.</p>
      <h2 id="041419ec-2e94-4aa6-9ad7-35f5115bb597" class="">Chat</h2>
      <p id="a9747b0e-7418-4aea-9d06-8c6ead040382" class="">S tÃ­m pÅ™ichÃ¡zÃ­ pÅ™ekvapivÄ› vysokÃ¡ uÅ¾iteÄnost chatu. Chat nenÃ­ nÄ›jakÃ¡ radikÃ¡lnÄ› novÃ¡ funkcionalita, ale jen zpÅ¯sob jakÃ½m je pouÅ¾Ã­vÃ¡no auto-doplÅˆovÃ¡nÃ­. NapÅ™Ã­klad v <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> najdeme v podsloÅ¾ce <code>prompts/</code> soubor <code>chat-with-bob.txt</code>. Ten mÃ¡ nÃ¡sledujÃ­cÃ­ obsah:</p>
      <pre id="0423cc15-6bb7-4dbc-8c3a-c21a7ea67b31" class="code code-wrap"><code>Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User's requests immediately and with precision.

User: Hello, Bob.
Bob: Hello. How may I help you today?
User: Please tell me the largest city in Europe.
Bob: Sure. The largest city in Europe is Moscow, the capital of Russia.
User:</code></pre>
      <p id="b18764e6-25f0-44c4-8199-6937e442947e" class="">CelÃ½ <em>chat mode</em> funguje ÃºplnÄ› triviÃ¡lnÄ› - prvnÄ› pÅ™edhodÃ­ sÃ­ti k doplÅˆovÃ¡nÃ­ pÅ™epis rozhovoru s AI asistentem, kde je na zaÄÃ¡tku nÄ›jakÃ½ <em>prompt</em>, potom nÃ¡sleduje ukÃ¡zka <em>formÃ¡tu</em> (otÃ¡zka, odpovÄ›Ä). Jakmile program narazÃ­ ve vÃ½stupu na pattern <code>User:</code>, pouÅ¾ije se jednoduchÃ½ pattern matching:</p>
      <pre id="84568ae0-dc4a-4d11-9aad-c996d19f92b0" class="code code-wrap"><code>-r PROMPT, --reverse-prompt PROMPT
     run in interactive mode and poll user input upon seeing PROMPT (can be
     specified more than once for multiple prompts).</code></pre>
      <p id="330e3ebc-32d3-4972-9f2b-d23bbd67f2a5" class="">Pokud najde string v tomhle parametru, naÄte trochu dat od uÅ¾ivatele, pÅ™idÃ¡ je k pÅ¯vodnÃ­mu dokumentu a pokraÄuje v doplÅˆovÃ¡nÃ­. TÃ­m vznikÃ¡ celÃ¡ iluze chatu, pÅ™estoÅ¾e model poÅ™Ã¡d jen dÃ¡l doplÅˆuje â€œpÅ™episâ€ rozhovoru ÄlovÄ›ka s umÄ›lou inteligencÃ­.</p>
      <p id="ff7f0934-54de-41df-a638-464b8a5c4dd8" class="">KdyÅ¾ se podÃ­vÃ¡te na ten <em>prompt</em>, tak tam je uveden kontext simulÃ¡toru - pÅ™epis konverzace s uÅ¾iteÄnÃ½m nÃ¡pomocnÃ½m asistentem, kterÃ½ mÃ¡ <em>formÃ¡t</em> stÅ™Ã­dajÃ­cÃ­ch se otÃ¡zek a odpovÄ›dÃ­. Model se tedy chovÃ¡ uÅ¾iteÄnÄ› a nÃ¡pomocnÄ›, protoÅ¾e doplÅˆuje pÅ™Ã­bÄ›h o tom jak by to vypadalo, kdyby se choval uÅ¾iteÄnÄ› a nÃ¡pomocnÄ›.</p>
      <p id="20855f43-d922-4373-b535-bc6d93b4fb39" class="">Z toho taky plyne Å¾e kdyÅ¾ se bavÃ­te s chatem na openAI, nemÃ¡te pÅ™Ã­stup k tomu jak vypadÃ¡ ten kontext. OvÅ¡em pokud jdete do <a href="https://platform.openai.com/playground">playgroundu</a>, mÅ¯Å¾ete si ten <em>prompt</em> do jistÃ© mÃ­ry nastavit (pÃ­Å¡u <em>do jistÃ©</em> <em>mÃ­ry</em>, protoÅ¾e OpenAI k tomu imho pÅ™idÃ¡vÃ¡ vlastnÃ­ <em>prompt</em>):</p>
      <figure id="a5195827-126d-45ce-8e11-36d60dd57e37" class="image">
        <a href="Screenshot_from_2023-04-11_10-34-44.png" title="Screenshot_from_2023-04-11_10-34-44.png"><img style="width:1220px" src="Screenshot_from_2023-04-11_10-34-44_thumb.jpg"></a>
      </figure>
      <p id="2baf03b8-83f8-451b-9b75-5e3a8bc02bc0" class="">Zde je ukÃ¡zka reakce s jinÃ½m <em>promptem</em>:</p>
      <figure id="7414901b-307f-40b1-9e96-b85aa948bd28" class="image">
        <a href="Screenshot_from_2023-04-11_10-34-21.png" title="Screenshot_from_2023-04-11_10-34-21.png"><img style="width:1210px" src="Screenshot_from_2023-04-11_10-34-21_thumb.jpg"></a>
      </figure>
      <p id="dc2b6399-e625-4178-bf5c-9f2bb4ca455d" class=""><em>Prompty</em> taky mÅ¯Å¾ou uvÃ¡dÄ›t podstatnÄ› sloÅ¾itÄ›jÅ¡Ã­ <em>formÃ¡t</em>, napÅ™Ã­klad jde simulovat jakÃ©si hlubÅ¡Ã­ pÅ™emÃ½Å¡lenÃ­ nad otÃ¡zkami, viz <a href="https://github.com/ggerganov/llama.cpp/blob/master/prompts/reason-act.txt">llama.cpp/prompts/reason-act.txt</a>:</p>
      <pre id="100d689f-dfe0-4fe6-bffa-52925d5bc43c" class="code code-wrap"><code>You run in a loop of Thought, Action, Observation.
At the end of the loop either Answer or restate your Thought and Action.
Use Thought to describe your thoughts about the question you have been asked.
Use Action to run one of these actions available to you:
- calculate[python math expression]
Observation will be the result of running those actions


Question: What is 4 * 7 / 3?
Thought: Do I need to use an action? Yes, I use calculate to do math
Action: calculate[4 * 7 / 3]
Observation: 9.3333333333
Thought: Do I need to use an action? No, have the result
Answer: The calculate tool says it is 9.3333333333
Question: What is capital of france?
Thought: Do I need to use an action? No, I know the answer
Answer: Paris is the capital of France
Question:</code></pre>
      <p id="0cc27aab-fe86-48d6-8606-1452cda2d024" class="">Tedy model se jen nesnaÅ¾Ã­ dÃ¡t odpovÄ›Ä, ale prvnÄ› se <em>ZamyslÃ­</em>, potom naplÃ¡nuje <em>Akci,</em> nÃ¡sledovanou <em>PozorovÃ¡nÃ­m</em>, po kterÃ©m se znovu <em>ZamyslÃ­</em> a nakonec poskytne <em>OdpovÄ›Ä</em>. TÃ­mhle je moÅ¾nÃ© obejÃ­t nÄ›kterÃ© nedostatky modelu, jako napÅ™Ã­klad krÃ¡tkodobou pamÄ›Å¥, nebo problÃ©my s dlouhodobÃ½m plÃ¡novÃ¡nÃ­m.</p>
      <h2 id="d45ce5de-1697-47de-b9a0-a957dc050f43" class="">Human alignment & shoggoth</h2>
      <p id="fdeb9e40-7eac-4f20-abc6-97ab2d59f78a" class="">S <em>chat modem</em> se ukÃ¡zalo, Å¾e existujÃ­cÃ­ LLM mÅ¯Å¾ou fungovat jako uÅ¾iteÄnÃ¡ AI, akorÃ¡t jsou ÃºplnÄ› cizÃ­ naÅ¡emu oÄekÃ¡vÃ¡nÃ­ a Äasto nedÄ›lajÃ­ co po nich chceme.</p>
      <p id="887ec62d-36e4-4278-80fb-763da70dd03d" class="">ZajÃ­mavÃ½ vÃ½voj poslednÃ­ch asi pÅ¯l roku je, Å¾e se dajÃ­ pomÄ›rnÄ› rychle ohnout pomocÃ­ <a href="https://huggingface.co/blog/rlhf">RLHF</a> (Reinforcement Learning from Human Feedback), tedy nÄ›co jako <em>uÄenÃ­ z lidskÃ© zpÄ›tnÃ© vazby</em>. To spoÄÃ­vÃ¡ v tom, Å¾e pÅ¯vodnÃ­ fungujÃ­cÃ­ model se rozÅ¡Ã­Å™Ã­ nÄ›jakou dalÅ¡Ã­ vrstvou kterÃ¡ udÃ¡vÃ¡ <em>vhodnost</em> odpovÄ›di, a pak se douÄÃ­ na rÅ¯znÃ½ch ukÃ¡zkÃ¡ch konverzacÃ­ <em>pÅ™ijatelnÃ© chovÃ¡nÃ­</em>. Model se neuÄÃ­ novÃ¡ fakta, nebo novÃ½m zpÅ¯sobem uvaÅ¾ovat o svÄ›tÄ›, ale v podstatÄ› co od nÄ›j chceme, co je pro lidi relevantnÃ­ a co nenÃ­. <em>Human alignment</em> (<em>pÅ™Ã­klon k lidskosti?</em>).</p>
      <p id="6c94e0fc-d10a-4e56-a142-fe4c5ec0b44f" class="">Tak vznikl meme Shoggoth, pÅ™Ã­Å¡ery s lidskou maskou, protoÅ¾e na pozadÃ­ je to poÅ™Ã¡d nÄ›co ÃºplnÄ› cizÃ­ho, simulÃ¡tor kterÃ©mu byla nasazena pÅ™Ã­vÄ›tivÃ¡ maska:</p>
      <div id="0e8314e4-9650-4f52-b04f-3ffe00a911d5" class="column-list">
        <div id="00306cd7-2118-40ef-adde-68c4e28d2049" style="width:33.333333333333336%" class="column">
          <figure id="dd7d9780-aa9e-42d2-bbdf-71ee5bae482d" class="image">
            <a href="FqZ6ud1WcAMvZvt.jpeg" title="FqZ6ud1WcAMvZvt.jpeg"><img style="width:1400px" src="FqZ6ud1WcAMvZvt_thumb.jpg"></a>
            <figcaption>
              <em>(Source:</em> <em><a href="https://twitter.com/mealreplacer/status/1632126858299863040">https://twitter.com/mealreplacer/status/1632126858299863040</a></em><em>)</em>
            </figcaption>
          </figure>
        </div>
        <div id="65885ae1-6203-461c-8032-5e8d6c646a6e" style="width:33.333333333333336%" class="column">
          <figure id="7b6bb1a5-6c28-463e-96ed-8230e7094e6d" class="image">
            <a href="Fsvsl4AWcAA6xo7.jpeg" title="Fsvsl4AWcAA6xo7.jpeg"><img style="width:708px" src="Fsvsl4AWcAA6xo7.jpeg"></a>
            <figcaption>
              <em>(Source:</em> <em><a href="https://twitter.com/LionTNC/status/1642666630831276035">https://twitter.com/LionTNC/status/1642666630831276035</a></em><em>)</em>
            </figcaption>
          </figure>
        </div>
        <div id="7419d5f1-c8d5-434f-9c6a-c2c7ad8a95b6" style="width:33.33333333333333%" class="column">
          <figure id="0ef468b0-d144-4a5c-8aea-df4d5563b1b5" class="image">
            <a href="407.jpg" title="407.jpg"><img style="width:2118px" src="407_thumb.jpg"></a>
          </figure>
        </div>
      </div>
      <div id="9d45751c-04e5-49eb-adbc-185bbb9a141c" class="column-list">
        <div id="e0d7fe95-729b-416b-be4b-772fc392003e" style="width:37.5%" class="column">
          <figure id="b1e2bd9b-fa3f-46d5-8afb-01f52d79eca5" class="image">
            <a href="FtOw0qtXoAU0XpK.png" title="FtOw0qtXoAU0XpK.png"><img style="width:652px" src="FtOw0qtXoAU0XpK.png"></a>
            <figcaption>
              <em>(Source:</em> <em><a href="https://twitter.com/JCorvinusVR/status/1644852722611486720">https://twitter.com/JCorvinusVR/status/1644852722611486720</a></em><em>)</em>
            </figcaption>
          </figure>
        </div>
        <div id="0908610e-0ead-412d-b862-bdd4a4abecc0" style="width:62.5%" class="column">
          <figure id="65a3352d-ddcf-46b8-9b69-1730ef4a2abc" class="image">
            <a href="FoO-U_gaYAAIlPZ.jpeg" title="FoO-U_gaYAAIlPZ.jpeg"><img style="width:793px" src="FoO-U_gaYAAIlPZ.jpeg"></a>
            <figcaption>
              <em>(Source:</em> <em><a href="https://twitter.com/anthrupad/status/1622349563922362368">https://twitter.com/anthrupad/status/1622349563922362368</a></em><em>)</em>
            </figcaption>
          </figure>
        </div>
      </div>
      <div id="4225640a-dbd5-4447-a8dc-052ec5fa0e3c" class="column-list">
        <div id="d49f4f58-130f-47ec-84f2-f920f63ff54a" style="width:50%" class="column">
          <figure id="8b27f5d8-048b-4a98-8ba5-a8a0940c84ba" class="image">
            <a href="4bb.jpg" title="4bb.jpg"><img style="width:1436px" src="4bb_thumb.jpg"></a>
          </figure>
        </div>
        <div id="7cfbcd81-ab46-4216-b0e1-2653cb904901" style="width:50%" class="column">
          <figure id="0c0b7dc6-bcc5-484f-bcc7-8d807ae282be" class="image">
            <a href="18c.jpg" title="18c.jpg"><img style="width:1750px" src="18c_thumb.jpg"></a>
          </figure>
        </div>
      </div>
      <p id="481a05d5-9de3-4d43-a24b-0b72a23b1089" class="">Ty obrÃ¡zky jsou cute, ale jak uÅ¾ poznamenal nÄ›kdo na twitteru, jsou principiÃ¡lnÄ› Å¡patnÃ¡ analogie. SprÃ¡vnÃ© zobrazenÃ­ by bylo mÃ­sto mnoha oÄÃ­ mÃ­t mnoho masek, protoÅ¾e Shoggoth sÃ¡m o sobÄ› v podstatÄ› nenÃ­.</p>
      <figure id="e783b3b5-6fb4-43e9-b877-8ef1476169ae" class="image">
        <a href="e3b.jpg" title="e3b.jpg"><img style="width:900px" src="e3b.jpg"></a>
      </figure>
      <p id="1a3064f3-0275-4d7a-871b-2234c1fa2c6a" class="">Je to nÄ›co jako hlas vÅ¡ech textÅ¯ lidstva s maskou vÅ¡ech postav vÅ¡ech pÅ™Ã­bÄ›hÅ¯. Tomu nÄ›kdo navrch nasprejoval smajlÃ­ka ve tvaru chatbota, se kterÃ½m si myslÃ­te, Å¾e si povÃ­dÃ¡te.</p>
      <p id="72e03c31-fe35-476b-ba1e-39d578bb4c8b" class="">To nemyslÃ­m tak jako <em>â€œberte informace s rezervouâ€</em>, nebo <em>â€œnespolÃ©hejte na nÄ›â€</em>, ale spÃ­Å¡ jako Å¾e nÃ¡tura Shoggotha je Shoggoth. Shoggoth musÃ­ simulovat, aby doplÅˆoval text. KdyÅ¾ nechÃ¡pe, tak ve vÄ›tÅ¡inÄ› pÅ™Ã­padÅ¯ vypadl z role a nevÃ­ co mÃ¡ pÅ™edstÃ­rat. MusÃ­te mu ten kontext uvÃ©st. Ne kontext rozhovoru, ale toho co mÃ¡ bÃ½t, jako co mÃ¡ vÃ©st rozhovor. Meh.</p>
      <h2 id="0aa82e8d-bc4a-42e0-a808-8ab11da6b9fb" class="">MalÃ© modely, proÄ a jak fungujÃ­</h2>
      <p id="a52d3161-cf73-4844-bd4d-4a3dff0a1fa4" class="">ÄŒlÃ¡nek <a href="https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications">chinchilla's wild implications</a> ukazuje na proÄ nenÃ­ poÄet vah (parametrÅ¯) ÃºplnÄ› smÄ›rodatnÃ¡ metrika, kterÃ¡ by mÄ›la bÃ½t cÃ­lem, a Å¾e vÃ­c dat vyhrÃ¡vÃ¡ nad vÄ›tÅ¡Ã­m mnoÅ¾stvÃ­m <em>parametrÅ¯</em> modelu.</p>
      <p id="987e523b-59c1-4987-b967-6e232d7d0bcc" class="">PonÄ›kud pÅ™ekvapivÄ› se ukÃ¡zalo, Å¾e kdyÅ¾ ÄlovÄ›k vezme tyhle <em>human alignment</em> data a nacpe je do vÃ½raznÄ› menÅ¡Ã­ch modelÅ¯, tak se jde v rÅ¯znÃ½ch benchmarcÃ­ch dostat nÄ›kam na ÃºroveÅˆ lehce pod GPT3. GPT3 je 175B, GPT4 je ÃºdajnÄ› 6x vÄ›tÅ¡Ã­, ale ÄÃ­sla jsem nenaÅ¡el, nÄ›kdo tvrdÃ­ Å¾e mÃ¡ 10x vÃ­c parametrÅ¯. â€œBâ€ v popisu je tam pro anglickÃ½ <em>billion</em>, Äesky <em>miliarda</em> (parametrÅ¯).</p>
      <p id="13be2104-3c8f-4575-9700-3c5149ac3260" class="">Story za tÃ­m;</p>
      <p id="d386a67b-c95e-48e9-8579-11c23d37bf2d" class="">Facebook (Meta AI, ehm) vytvoÅ™il set relativnÄ› malÃ½ch <em><a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">llama</a></em> modelÅ¯ 7B, 13B, 33B, a 65B, kterÃ© natrÃ©novali tak nÄ›jak standardnÃ­m zpÅ¯sobem. Pak to vÅ¡echno +- zveÅ™ejnili. PÅ¯vodnÄ› asi ÃºplnÄ›, zpÄ›tnÄ› se v shitstormu kolem veÅ™ejnosti diskutujÃ­cÃ­ ohlednÄ› zneuÅ¾itÃ­ GPT4 rozhodli ho dÃ¡vat jen po vyplnÄ›nÃ­ formulÃ¡Å™e dalÅ¡Ã­m <em>vÃ½zkumnÃ­kÅ¯m (.edu mail je velkÃ© plus)</em>. SamozÅ™ejmÄ› se stalo oÄividnÃ© a modely jsou Å¡Ã­Å™eny vÅ¡ude moÅ¾nÄ› (torrent, mrk mrk).</p>
      <p id="c9fca292-a491-4cdc-a680-a700cecf30c3" class="">Lidi ze Standfordu vzali ten nejmenÅ¡Ã­ <em>llama</em> 7B model a pouÅ¾ili na nÄ›m <a href="https://arxiv.org/pdf/2212.10560.pdf">self-instruct</a> fine tuning, ÄÃ­mÅ¾ stvoÅ™ili <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpacu</a>.</p>
      <figure id="05863919-b125-4e24-985b-00122b426cfd">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/xslW5sQOkC8" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <p id="63a6814c-2834-4a3d-b156-8c7eb09db56e" class="">Na tomhle je zajÃ­mavÃ©, Å¾e narozdÃ­l od pÅ¯vodnÃ­ho RLHF, kterÃ© probÃ­halo formou tisÃ­ce hodnocenÃ½ch konverzacÃ­ s uÅ¾ivateli ve stylu <em>â€œuÅ¾ivatel si s modelem povÃ­dÃ¡, pak vybere jestli dobrÃ½ nebo Å¡patnÃ½, model se pak trÃ©nuje aby dÄ›lal vÃ­c dobrÃ½ a mÃ­Åˆ Å¡patnÃ½â€</em> k tomu pouÅ¾ili GPT3.5. Tedy <em>â€œjeden model trÃ©nuje druhÃ½ model na dobrÃ½ a Å¡patnÃ½â€</em>. TÃ­m byl pronesen ÃºvodnÃ­ pÅ™Ã­pitek veÄÃ­rku <a href="https://cs.wikipedia.org/wiki/Technologick%C3%A1_singularita">Singularity</a> (bÃ¡jnÃ½ stav, kdy naÅ¡e technologie zaÄne vylepÅ¡ovat sebe sama).</p>
      <figure id="24b14980-9a03-4c06-bd29-9da19b276037" class="image">
        <a href="Untitled_2.png" title="Untitled_2.png"><img style="width:599px" src="Untitled_2.png"></a>
      </figure>
      <p id="5a8275cb-e5d4-4d64-8d1d-e41d88a66c5b" class="">PÅ™ekvapivÄ› se ukÃ¡zalo, Å¾e staÄÃ­ asi 52 tisÃ­c tÄ›hle ukÃ¡zek, tedy v podstatÄ› nic ve srovnÃ¡nÃ­ s mnoÅ¾stvÃ­m ostatnÃ­ch trÃ©novacÃ­ch dat, a model se dostÃ¡vÃ¡ v benchmarcÃ­ch a automatizovanÃ½ch testech o desÃ­tky procent blÃ­Å¾ k Ãºrovni GPT3.</p>
      <p id="695b4a0d-cd29-4856-99a4-8436e1e76a78" class="">Alpaca potom byla <a href="https://github.com/tatsu-lab/stanford_alpaca">uvolnÄ›na</a> super divnÃ½m zpÅ¯sobem; protoÅ¾e pÅ¯vodnÃ­ model byl facebooku a ten ho pÅ™estal Å¡Ã­Å™it, uvolnili v podstatÄ› jen nÄ›co jako diff od <em>llamy</em>. Tedy k tomu aby se dal rozchodit bylo potÅ™eba nÄ›kde sehnat <em>llamu</em>. VÅ¡ichni se plÃ¡cali po zÃ¡dech, jak jsou zodpovÄ›dnÃ­ a brÃ¡nÃ­ Å¡Ã­Å™enÃ­ spamu a dezinformacÃ­. To jim vydrÅ¾elo pÅ™ibliÅ¾nÄ› do druhÃ©ho dne, neÅ¾ to nÄ›kdo zkombinoval a hodil na net.</p>
      <p id="b3307b73-4848-4592-9720-a81f591a9525" class=""><em>Podle mÃ©ho souÄasnÃ©ho nÃ¡zoru</em> tohle vÅ¡echno znamenÃ¡, Å¾e ty Å¾Ã¡danÃ© a zajÃ­mavÃ© schopnosti jsou i v menÅ¡Ã­ch modelech. Ta tÄ›Å¾kÃ¡ ÄÃ¡st, kterÃ¡ byla dosud Å™eÅ¡ena ÄÃ­m dÃ¡l vÄ›tÅ¡Ã­m poÄtem parametrÅ¯ spoÄÃ­vÃ¡ do jistÃ© mÃ­ry ÄistÄ› v tom aby ten model vyabstrahoval co po nÄ›m vlastnÄ› chcem. CoÅ¾ tam jde dohackovat mnohem levnÄ›ji.</p>
      <p id="3c12fb54-8883-4ee5-a324-c477fd51cbd6" class="">Co ovÅ¡em zavÄ›tÅ™ila asi tak pÅ¯lka internetu nebyl ani tak samotnÃ½ model, ale informace Å¾e:</p>
      <blockquote id="53b396e9-8d36-4ce9-8441-838741b3f49c" class="">
        <em>Alpaca behaves qualitatively similarly to OpenAIâ€™s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$).</em>
      </blockquote>
      <blockquote id="40f04410-b8de-4fef-8df4-4f39dc61e726" class="">
        <em>while being surprisingly small and easy/cheap to reproduce (&lt;600$).</em>
      </blockquote>
      <blockquote id="6e1e8991-c4b2-4562-9143-70ee224e937e" class="">
        <em>cheap to reproduce (&lt;600$).</em>
      </blockquote>
      <blockquote id="7edf7b7d-5b85-43c5-a750-3d3ff417ab89" class="">
        <em>600$</em>
      </blockquote>
      <p id="47b6e9e8-d5ad-4701-8ece-df6d5b04215f" class="">Jen pro kontext, tÃ©hle ÃºrovnÄ› funkcionality se u vÄ›tÅ¡Ã­ch modelÅ¯ se pohybuje v Å™Ã¡du milionÅ¯ dolarÅ¯. Party zaÄala. BÄ›hem poslednÃ­ch pÃ¡r tÃ½dnÅ¯ probÄ›hlo kvaÅ¡enÃ­, jehoÅ¾ vÃ½sledkem je mimo jinÃ©:</p>
      <ol type="1" id="a7ec007d-477e-4384-9eb1-4a7a298aaa84" class="numbered-list" start="1">
        <li>
          <a href="https://www.reddit.com/r/LocalLLaMA/">r/LocalLLaMA</a> subreddit vÄ›novanÃ½ provozovÃ¡nÃ­, pouÅ¾Ã­vÃ¡nÃ­ a trÃ©novÃ¡nÃ­ malÃ½ch modelÅ¯
        </li>
      </ol>
      <ol type="1" id="05e00e6e-91ea-456c-a605-0247d07efd1e" class="numbered-list" start="2">
        <li>
          <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> pÅ™epis python kÃ³du do C++, takÅ¾e bÄ›Å¾Ã­ podstatnÄ› rychleji i na CPU
        </li>
      </ol>
      <ol type="1" id="0ae44b35-a974-420f-bec5-8d85fa172c49" class="numbered-list" start="3">
        <li>
          <a href="https://www.reddit.com/r/Oobabooga/">r/Oobabooga</a> a <a href="https://github.com/oobabooga/text-generation-webui/">Text generation web UI</a> (user friendly web UI ve stylu <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">stable-diffusion-webui</a>)
        </li>
      </ol>
      <ol type="1" id="93923a74-b875-41fb-8986-675e0e4c76e7" class="numbered-list" start="4">
        <li>
          <a href="https://vicuna.lmsys.org/">Vicuna</a> (v dobÄ› ÄlÃ¡nku asi nejschopnÄ›jÅ¡Ã­ malÃ½ model)
        </li>
      </ol>
      <ol type="1" id="b932c8de-8d3f-4cb9-bdd8-400ccc0d0a58" class="numbered-list" start="5">
        <li>
          <a href="https://github.com/nomic-ai/gpt4all">GPT4All</a> llama model natrÃ©novanÃ½ na ~800k GPT3 konverzacÃ­ch, s binÃ¡rkami i scripty i modely a vÅ¡Ã­m
        </li>
      </ol>
      <ol type="1" id="c8e99791-59c4-40b2-98ed-60dc1f5841f6" class="numbered-list" start="6">
        <li>
          <a href="https://github.com/tloen/alpaca-lora">Alpaca-LoRA</a> alternativa k alpace za pouÅ¾itÃ­ <a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA</a> (specifickÃ½ zpÅ¯sob jak trÃ©novat existujÃ­cÃ­ modely)
        </li>
      </ol>
      <ol type="1" id="659b436c-8e61-4b8b-922d-e3263a83f014" class="numbered-list" start="7">
        <li>
          <a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM">GPT-4-LLM</a> trÃ©novacÃ­ data pro <em>fine tuning</em> modelÅ¯
        </li>
      </ol>
      <ol type="1" id="b46a59be-1459-4616-9dea-140a7a7f3c5e" class="numbered-list" start="8">
        <li>
          <a href="https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered">ShareGPT_Vicuna_unfiltered</a> trÃ©novacÃ­ data ze kterÃ½ch bylo vyhozeno filtrovÃ¡nÃ­ (sex, rasismus a tak podobnÄ›)
        </li>
      </ol>
      <p id="ed77b074-a37c-4970-8060-3acd6af6c4b4" class="">a kaÅ¾dÃ½ den nÄ›co dalÅ¡Ã­ho.</p>
      <p id="20e20e9a-5d71-457a-aa56-2c7b5fb29bc3" class="">Mimochodem, tohle je jeden z tÄ›ch ÃºÅ¾asnÃ½ch momentÅ¯ <em>na rozhranÃ­</em>. KdyÅ¾ se nÄ›co mÄ›nÃ­. TakovÃ¡ ta chvÃ­le co se zdÃ¡ divokÃ¡, ale ÄlovÄ›k na to zpÄ›tnÄ› vzpomÃ­nÃ¡. NÄ›co jako nostalgickÃ© devadesÃ¡tky, nebo zaÄÃ¡tek bitcoinu. Ta doba co srÅ¡Ã­ potenciÃ¡lem, vÄ›ci nejsou jasnÄ› danÃ© a vÅ¡echno je zdÃ¡nlivÄ› moÅ¾nÃ©. Chce se to chvÃ­li zastavit a ocenit tenhle okamÅ¾ik, protoÅ¾e typicky vÃ¡m to dojde aÅ¾ zpÄ›tnÄ›. OtevÃ­rajÃ­ se novÃ© dimenze (<a href="../../Ostatni/Vytvareni_prostoru_oteviranim_dimenzi.html" title="VytvÃ¡Å™enÃ­ prostorÅ¯ otevÃ­rÃ¡nÃ­m dimenzÃ­">VytvÃ¡Å™enÃ­ prostorÅ¯ otevÃ­rÃ¡nÃ­m dimenzÃ­</a>), kolabujÃ­ a tak. Fakt cool.</p>
      <h2 id="840fdbed-348f-4a00-a8fa-d62b289726a5" class="">Jak rozjet lokÃ¡lnÃ­ model</h2>
      <p id="2b36e123-1c6d-4530-a522-4ff983b986ba" class="">Tenhle ÄlÃ¡nek jsem pÅ¯vodnÄ› zaÄal psÃ¡t, protoÅ¾e jsem to doma zkouÅ¡el a bylo to docela sloÅ¾itÃ©. BÄ›hem doby co jsem ho psal se vÅ¡echno natolik zjednoduÅ¡ilo, Å¾e pÅ¯vodnÃ­ text totÃ¡lnÄ› ztratil smysl.</p>
      <p id="dfd6caeb-9e1a-4677-99e9-54de799dcfee" class="">Rozjedeme si teÄ Vicunu (nebo si <a href="https://www.reddit.com/r/LocalLLaMA/wiki/models/">tady</a> vyberte nÄ›co jinÃ©ho).</p>
      <p id="c3687d55-9411-41cb-bdd9-3474c40b87dc" class="">NÄ›kam na NVMe, kde mÃ¡mÄ› aspoÅˆ sto giga mÃ­sta si prvnÄ› naklonujeme <a href="https://github.com/oobabooga/text-generation-webui/">textgeneration-web-ui</a>:</p>
      <pre id="861a831a-efb8-4539-9118-c1fdb04372ad" class="code code-wrap"><code>git clone https://github.com/oobabooga/text-generation-webui.git</code></pre>
      <p id="e2afdb5b-a464-4280-8b5e-7fa0fde707be" class="">PÅ™ejdeme do sloÅ¾ky <code>models/</code> a dÃ¡me klonovat Vicunu:</p>
      <pre id="b607f695-0938-4d85-8476-16d837002c64" class="code code-wrap"><code>git clone https://huggingface.co/eachadea/vicuna-13b</code></pre>
      <p id="d7b377f4-a518-4330-93dc-0426b0450789" class="">JednÃ¡ se o pytorch model. ZatÃ­mco se klonuje, otevÅ™eme si dalÅ¡Ã­ terminÃ¡l, a nainstalujeme si zÃ¡vislosti. PrvnÄ› minicondu (nebo anacondu):</p>
      <pre id="fcf9abc7-75c0-4832-b45b-2667e88b5fd2" class="code code-wrap"><code>curl -sL "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh" &gt; "Miniconda3.sh"
bash Miniconda3.sh</code></pre>
      <p id="287f8e3b-8344-4c7e-889e-64845ac4881a" class="">Potom nÄ›jakÃ© ty nutnosti pro buildovÃ¡nÃ­:</p>
      <pre id="13d7163d-f5ea-4476-b0b1-61504561ca7a" class="code code-wrap"><code>sudo apt install build-essential</code></pre>
      <p id="b3112a70-f791-4119-90dd-c36927235b7f" class="">VyrobÃ­me si novÃ½ <code>conda</code> environment:</p>
      <pre id="bb440199-12d0-4e84-8d69-8270962a97df" class="code code-wrap"><code>conda create -n textgen python=3.10.9
conda activate textgen</code></pre>
      <p id="67242636-db6c-4b7b-abea-53350793c452" class="">V nÄ›m pak nainstalujeme zÃ¡vislosti:</p>
      <pre id="f7b75ae9-72ec-4727-b3d1-7d4289c634d6" class="code code-wrap"><code>pip3 install torch torchvision torchaudio
pip install -r requirements.txt</code></pre>
      <p id="d00031e9-aa68-4a4b-ac5e-2cec39d0f53e" class="">No a to je vÅ¡echno. PoÄkÃ¡me aÅ¾ se model stÃ¡hne a pak to celÃ© spustÃ­me:</p>
      <pre id="e03f7116-c3e5-4b32-81cb-d412ebd21875" class="code code-wrap"><code>python server.py --cpu</code></pre>
      <p id="ec230c8e-0130-45d1-b32a-efffebcd4b8d" class="">Parametr <code>--cpu</code> je moÅ¾nÃ© vynechat, pokud mÃ¡te grafickou kartu s 24G VRAM.</p>
      <pre id="7612ab64-8f44-4a99-84e3-a1c250311acd" class="code code-wrap"><code>$ python server.py --cpu --chat

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 117
CUDA SETUP: Loading binary /home/bystrousak/anaconda3/envs/textgen/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...
Loading vicuna-13b...
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14&lt;00:00,  4.95s/it]
Loaded the model in 15.10 seconds.
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.</code></pre>
      <p id="20cc8734-4aca-42b7-8f19-541b605fb3c9" class="">Na portu <code>7860</code> nabÄ›hlo webovÃ© rozhranÃ­:</p>
      <figure id="dda34ec2-0792-4132-af21-eafdb88b0842" class="image">
        <a href="Screenshot_from_2023-04-12_01-23-02.jpg" title="Screenshot_from_2023-04-12_01-23-02.jpg"><img style="width:1201px" src="Screenshot_from_2023-04-12_01-23-02_thumb.jpg"></a>
      </figure>
      <p id="1ea5c46d-0a1f-4c4f-a30b-bdb321828ebe" class="">Slova se u mÄ› objevujÃ­ velmi pomalu, asi tak jedno za pÄ›t vteÅ™in. PostupnÄ› se naÄÃ­tÃ¡ po znacÃ­ch, jak ho model generuje. ChtÄ›lo by to grafickou kartu s vÄ›tÅ¡Ã­ pamÄ›tÃ­, do mojÃ­ 3090Ti se model nevleze.</p>
      <h3 id="e5fe1d77-42d1-484e-8083-13ee9198c03b" class="">llama.cpp</h3>
      <p id="ab949baa-b40a-44df-ae42-324d6d39b35a" class="">NaÅ¡tÄ›stÃ­ je tu jeÅ¡tÄ› <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>, C++ pÅ™epis python kÃ³du:</p>
      <pre id="c0301978-6ece-41c5-a04e-f71be89fd755" class="code code-wrap"><code>git clone https://github.com/ggerganov/llama.cpp.git</code></pre>
      <p id="29d631cb-be9c-41c2-a72d-c2d9d8347399" class="">Pak jÃ­ zbuildÃ­me pÅ™Ã­kazem <code>make</code>.</p>
      <p id="c706b468-476e-4249-85fd-ea7e177d6add" class="">MenÅ¡Ã­ problÃ©m je, Å¾e <code>llama.cpp</code> pouÅ¾Ã­vÃ¡ optimalizovanÃ½ formÃ¡t uklÃ¡dÃ¡nÃ­ dat, kterÃ½ musÃ­me z pÅ¯vodnÃ­ho pytorch tensoru (<code>.pth</code>) pÅ™ekonvertovat na <code>.ggml</code>. V <code>llama.cpp</code> jsou na to rÅ¯znÃ© konverznÃ­ scripty, kterÃ© ovÅ¡em bohuÅ¾el nefungujÃ­:</p>
      <pre id="5245a568-b657-4fe6-b5fd-603371696316" class="code code-wrap"><code>$ python3 convert-pth-to-ggml.py ../models/vicuna-13b 0
Traceback (most recent call last):
  File "/media/bystrousak/internal_nvm/llama.cpp/convert-pth-to-ggml.py", line 274, in &lt;module&gt;
    main()
  File "/media/bystrousak/internal_nvm/llama.cpp/convert-pth-to-ggml.py", line 239, in main
    hparams, tokenizer = load_hparams_and_tokenizer(dir_model)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/media/bystrousak/internal_nvm/llama.cpp/convert-pth-to-ggml.py", line 102, in load_hparams_and_tokenizer
    with open(fname_hparams, "r") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../models/vicuna-13b/params.json'</code></pre>
      <p id="d10e36dd-edf7-4cce-9bba-40737998d426" class="">ChybÃ­ nÃ¡m <code>params.json</code>, kterÃ© jsem sice nÄ›kde naÅ¡el, ale pak chybÃ­ zase nÄ›co jinÃ©ho a pak zase nÄ›co dalÅ¡Ã­ho. V <a href="https://github.com/ggerganov/llama.cpp/pull/545">#545</a> je novÃ½ script <a href="https://github.com/ggerganov/llama.cpp/blob/b9c372dc7b571120e50cb1085fa05e0b209eeef5/convert.py">convert.py</a>. Ten si stÃ¡hnÄ›te do <code>llama.cpp</code>.</p>
      <p id="7bb5d626-a74b-4726-9500-e164064d0861" class="">Aktivujeme zase <code>textgen</code> condu z pÅ™edchozÃ­ kapitoly.</p>
      <pre id="6c2f12dd-f12b-4a92-b2e6-fae864284ce2" class="code code-wrap"><code>$ conda activate textgen</code></pre>
      <p id="c7c4a236-2e52-4e0d-96c6-beead25bb625" class="">PÅ™i spuÅ¡tÄ›nÃ­ si stÄ›Å¾uje Å¾e chybÃ­ soubor <code>added_tokens.json</code>:</p>
      <pre id="eb384d7e-88c3-4290-ba83-22f48c3aa4aa" class="code code-wrap"><code>Exception: Vocab size mismatch (model has 32001, but ../models/vicuna-13b/tokenizer.model has 32000).  Most likely you are missing added_tokens.json (should be in ../models/vicuna-13b).</code></pre>
      <p id="a7e58fec-53be-43db-880a-cc28de0b092c" class="">TakÅ¾e ho tam pÅ™idÃ¡me:</p>
      <pre id="82ea6a17-146f-4557-b3e8-eadcffc476c2" class="code code-wrap"><code>{
    "&lt;unk&gt;": 32000
}</code></pre>
      <p id="30b7ec7d-b5b5-4549-9c36-96072243d930" class="">Kde jsem to vzal? PoslednÃ­ hodnota v <code>tokenizer_config.json</code> ve sloÅ¾ce vicuny. ÃšplnÄ› random a netuÅ¡Ã­m jestli je to sprÃ¡vnÄ› (spÃ­Å¡ ne, ale +- to funguje).</p>
      <pre id="927a4171-18a4-4bec-9e9d-0b4d3e7861af" class="code code-wrap"><code>(textgen) $ python3 convert.py ../models/vicuna-13b --outtype f32</code></pre>
      <p id="82ccc5dc-58f7-4628-be90-b48c03702bb8" class="">CoÅ¾ vybleje soubor <code>../models/vicuna-13b/ggml-model-f32.bin</code>, ten se dÃ¡ potom uÅ¾ pustit pÅ™es <code>llama.cpp</code>. AlternativnÄ› je moÅ¾nÃ© dÃ¡t jako parametr <code>--outtype f16</code> pro menÅ¡Ã­ velikost, aby se vÃ¡m to veÅ¡lo do pamÄ›ti (ekvivalent <em>kvantizace</em> z jinÃ½ch projektÅ¯).</p>
      <p id="9509ce23-8658-4283-b77d-3797066527c8" class="">No a pak uÅ¾ to zbÃ½vÃ¡ jen spustit a hrÃ¡t si s tÃ­m:</p>
      <pre id="20350d04-13c4-4bf3-9474-c78a43154296" class="code code-wrap"><code>./main -m ../models/vicuna-13b/ggml-model-f32.bin --color --repeat_penalty 1.0 -i -t 15 -r "User:" -f prompts/chat-with-bob.txt</code></pre>
      <p id="ddf0cfc5-42ff-4faf-88be-b712d46458a7" class="">U mÄ› na poÄÃ­taÄi se text objevuje rychlostÃ­ asi jednoho slova za vteÅ™inu.</p>
      <h3 id="5e105158-a978-49c6-8087-7741b4eb50a1" class="">Nutno dodat</h3>
      <p id="46c4a241-3bd7-4d56-aefb-38a874ef2729" class="">MenÅ¡Ã­ modely jsou samozÅ™ejmÄ› mÃ©nÄ› schopnÃ©, ale nejsou ÃºplnÄ› neschopnÃ©. Pokud pozorujete divnÃ© chovÃ¡nÃ­, je moÅ¾nÃ©:</p>
      <ol type="1" id="9d55c72f-ae8e-4288-bccd-b80ecb1c0431" class="numbered-list" start="1">
        <li>MÃ¡te ne-ideÃ¡lnÄ› nastavenÃ© rÅ¯znÃ© vedlejÅ¡Ã­ hodnoty modelu. TÄ›ch je spousta a pokud jste je nenastavovali, tak je nÄ›kdo nastavil za vÃ¡s, a dost Äasto blbÄ›. Typicky <code>temperature</code> je nÄ›co co chcete mÃ­t nÄ›kde u <code>0.7</code>.
          <figure id="abe6b8d1-3816-4890-9115-6e870886e342" class="image">
            <a href="Screenshot_from_2023-04-12_02-05-28.png" title="Screenshot_from_2023-04-12_02-05-28.png"><img style="width:1049px" src="Screenshot_from_2023-04-12_02-05-28.png"></a>
          </figure>
        </li>
      </ol>
      <ol type="1" id="0f54b64d-ac18-4e8a-9f2a-edc2f5cc3a56" class="numbered-list" start="2">
        <li><em>Prompt</em>. Jak jsem vysvÄ›tloval, LLM jsou simulÃ¡tory. MÄ›jte poÅ™Ã¡d na pamÄ›ti, Å¾e nemluvÃ­te s ÄlovÄ›kem, mluvÃ­te se Shoggothem co simuluje AI asistenta. Chce to podle toho konstruovat kontext / prompt. Pokud tam Å¾Ã¡dnÃ½ nenastavÃ­te, tak je to Shoggoth a mÃ­sty mluvÃ­ neexistujÃ­cÃ­mi jazyky, mÃ­sty se opakuje a mÃ­sty bleje binÃ¡rnÃ­ duhu.</li>
      </ol>
      <ol type="1" id="f1df257c-83d8-42d4-9849-91cfa3648357" class="numbered-list" start="3">
        <li><em>Quantization</em>. Jde narazit na modely, kterÃ© majÃ­ v nÃ¡zvu nÄ›co ve stylu <code>4bit</code> a tak podobnÄ›. ÃšplnÄ› jsem to nestudoval, ale jestli to chÃ¡pu sprÃ¡vnÄ›, tak jsou to v podstatÄ› modely kde se vÃ¡hy neuronovÃ© sÃ­tÄ› pÅ™epoÄÃ­taly na 4bitovÃ¡ ÄÃ­sla, aby se to veÅ¡lo do pamÄ›ti. Tedy to ztratilo pÅ™esnost a z toho co jsem tak Äetl, tak to sice nÄ›jak funguje, ale obÄas dost hÅ¯Å™.</li>
      </ol>
      <ol type="1" id="15141499-a873-4af9-8b35-b96b50c69666" class="numbered-list" start="4">
        <li>MÅ¯Å¾ete mÃ­t model co prostÄ› za moc nestojÃ­. Z nÄ›kterÃ½ch byly vyhÃ¡zeny trÃ©novacÃ­ data v jinÃ½ch jazycÃ­ch neÅ¾ v angliÄtinÄ›, nÄ›kterÃ© byly pÅ™iohnuty tak Å¾e fungujÃ­ na nÄ›co skvÄ›le a na zbytek skoro vÅ¯bec.</li>
      </ol>
      <p id="2b8f5a79-3167-4b1e-b176-058b92c03d78" class="">Tady jsou konkrÃ©tnÃ­ ukÃ¡zky nÄ›kterÃ½ch problÃ©mÅ¯:</p>
      <pre id="fadd331c-663e-49ab-b332-126866aba913" class="code code-wrap"><code>Question: Convert to python: find . -name "*.md" -exec "cat {} &gt; blogs.md" \;
Thought: I think this is asking to find all files with the .md extension and then cat them into a single file called blogs.md
Action: I will use the find tool
Observation: The find tool found 5 files with the .md extension and the command cat'ed them into a single file called blogs.md</code></pre>
      <p id="74499aeb-c869-428a-a656-d14418de99c4" class="">Vicuna mÃ­sto aby to udÄ›lala, tak simulovala Å¾e nÄ›co dÄ›lÃ¡. Blbej kontext promptu. S <em>chat with bob</em> promptem:</p>
      <pre id="074f3c0a-d9f4-4761-83b7-c8d27362b270" class="code code-wrap"><code>User:Convert to python: find . -name "*.md" -exec "cat {} &gt; blogs.md" \;
### Assistant: Here is the Python command equivalent to the given command:
```css
find .</code></pre>
      <p id="f5ebbcc8-6240-4046-a207-40a695550a14" class="">OÄividnÄ› ÃºplnÄ› blbÄ›. TeÄ bych se mohl naÅ¡tvat a Å™Ã­ct si, Å¾e ten model je krÃ¡m na Ãºrovni GPT2 a vlastnÄ› k niÄemu.</p>
      <p id="61c89f1f-27f3-42b3-bbf0-973212f33645" class="">MÃ­sto toho mi doÅ¡lo Å¾e se bavÃ­m se Shoggothem, tak jsem to zkusil to znova a dal mu vÃ­c kontextu. MÃ­sto <em>â€œConvert to pythonâ€</em> jsem ho poÅ¾Ã¡dal <em>â€œConvert this shell command to python script, which will do the sameâ€</em>. A najednou to jde:</p>
      <pre id="68da8c40-e7de-4af6-83db-d4606f014720" class="code code-wrap"><code>User:Convert this shell command to python script, which will do the same: find . -name "*.md" -exec "cat {} &gt; blogs.md" \;
Bob: Here's the Python equivalent of the given shell command:
```python
import os

for file in os.scandir('.'):
    if file.is_file() and file.name.endswith('.md'):
        with open(file.name, 'rb') as f:
            content = f.read()
        with open('blogs.md', 'a') as f:
            f.write(content)
```
User:This doesn't work recursively.
Bob: You're right, the above code doesn't work recursively. Here's the updated Python code that recursively searches for `.md` files in all subdirectories of the current directory:
```python
import os

def find_and_cat_md_files(directory):
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.md'):
                file_path = os.path.join(root, file)
                with open(file_path, 'rb') as f:
                    content = f.read()
                with open('blogs.md', 'a') as f:
                    f.write(content)

find_and_cat_md_files('./')
```</code></pre>
      <p id="b066fb06-9330-46a6-a767-bb2fb3b7e472" class="">Ta funkcionalita tam byla celou dobu, co bylo Å¡patnÄ› je kontext. Kdybych uÅ¾ ze zaÄÃ¡tku vybral lepÅ¡Ã­ prompt neÅ¾ <em>chat with bob</em>, kde bych tÅ™eba uvedl Å¾e je to AI asistent kterÃ½ pomÃ¡hÃ¡ s programovÃ¡nÃ­m v pythonu, tak by to nejspÃ­Å¡ Å¡lo na prvnÃ­ dobrou. NÄ›co jako:</p>
      <pre id="2b66c6b9-0bd0-4c0d-a4a4-8bace3c774db" class="code code-wrap"><code>PÅ™epis rozhovoru ÄlovÄ›ka s chytrou AI, kterÃ¡ umÃ­ programovat a nikdy se neplete. OchotnÄ› plnÃ­ vÅ¡echny uÅ¾ivatelovy poÅ¾adavky a snaÅ¾Ã­ se bÃ½t tak uÅ¾iteÄnÃ¡, jak jen mÅ¯Å¾e.

User: nÄ›co chci
AI: takhle se to naprogramuje:
```python
#! /usr/bin/env python3

kÃ³d

```
User:</code></pre>
      <h2 id="d86676b9-fc73-4268-b92c-4b17fcd92bab" class="">Dva malÃ© modely</h2>
      <p id="5727b4b4-9b88-4c2d-910e-445f383ce347" class="">ZajÃ­mavÃ© use-cases z poslednÃ­ doby:</p>
      <ul id="c8ba3214-b501-4be6-ac02-9634598436eb" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://www.reddit.com/r/LocalLLaMA/comments/12c4hyx/introducing_medalpaca_language_models_for_medical/">Introducing MedAlpaca: Language Models for Medical Question-Answering</a>
        </li>
      </ul>
      <ul id="bd57e383-df74-41b0-a11d-7d048d7c0966" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://www.reddit.com/r/LocalLLaMA/comments/12gj0l0/i_trained_llama7b_on_unreal_engine_5s/">I trained llama7b on Unreal Engine 5â€™s documentation</a> (<a href="https://github.com/bublint/ue5-llama-lora">github</a>)
        </li>
      </ul>
      <p id="8ecffd47-0c9b-4676-b54d-3799629ca81c" class="">ObecnÄ› se dÃ¡ Å™Ã­ct, Å¾e docela dobrÃ½ use case pro tyhle malÃ© modely je natrÃ©novat je nad nÄ›jakÃ½m datasetem a pak je pouÅ¾Ã­vat jako search engine, kterÃ½ je schopnÃ½ do jistÃ© mÃ­ry odpovÃ­dat na otÃ¡zky ohlednÄ› tÄ›ch trÃ©novacÃ­ch dat. Taky je teoreticky schopnÃ½ hledat podle kontextu, ala Å¾e mu popÃ­Å¡ete co mÃ¡ funkce dÄ›lat a on jÃ­ najde.</p>
      <p id="1dc62743-43a1-4948-a40c-6bb7970d9279" class="">K trÃ©novÃ¡nÃ­ jsem zatÃ­m jeÅ¡tÄ› nedoiteroval, takÅ¾e snad v blogu nÄ›kdy pÅ™Ã­Å¡tÄ›.</p>
      <h1 id="93e87ffe-b903-4491-a35e-777205e8e78d" class="">GPT4</h1>
      <p id="935136af-8ebb-4139-acfd-cd9acf5f3a2c" class="">MalÃ© modely jsou cool a majÃ­ svoje pouÅ¾itÃ­, ale srovnÃ¡vat s GPT4 se tenhle pÃ¡r tÃ½dnÅ¯ starÃ½ vÃ½voj nedÃ¡.</p>
      <p id="db97da60-c389-4a62-9c04-66d77ac8f177" class="">Od doby co vyÅ¡el GPT4 Å™Ã­kÃ¡m poÅ™Ã¡d vÅ¡em Å¾e naprosto nemÃ¡ smysl ztrÃ¡cet Äas s GPT3 (GPT3.5). Ten rozdÃ­l je <em>brutÃ¡lnÃ­</em>.</p>
      <p id="5f972e71-2b83-4449-b646-b6c16cb9e5a1" class="">MÅ¯j osobnÃ­ pocit z toho je nÄ›kde mezi ohromenÃ­m, bÃ¡znÃ­, nostalgiÃ­ ze souÄasnosti pohledem budoucnosti (bylo fajn programovat, Å¡koda Å¾e uÅ¾ jsme u konce) a opilostÃ­ moÅ¾nostmi.</p>
      <h2 id="8b48cc21-6840-4f11-931e-4fc09d4024cb" class="">Kde vzÃ­t pÅ™Ã­stup k GPT4</h2>
      <p id="073a2c0f-12ed-4080-b19b-863c20efa8d9" class="">Jedna moÅ¾nost je samozÅ™ejmÄ› si zaplatit <em>chat plus</em>, ale to stojÃ­ 20$/mÄ›sÃ­c a mÃ¡ to momentÃ¡lnÄ› docela pÅ™Ã­snÃ½ rate limiting:</p>
      <blockquote id="47ed4fe4-3f76-4fc4-80b8-017593508121" class="">
        GPT-4 currently has a cap of 25 messages every 3 hours.
      </blockquote>
      <blockquote id="7cc01057-a7e0-4c9c-92d4-6faf02de1658" class="">
        GPT-4 mÃ¡ v souÄasnosti limit 25 zprÃ¡v kaÅ¾dÃ© 3 hodiny.
      </blockquote>
      <p id="27b39a00-be49-4ee9-a5d8-9e44c79d1e5b" class="">Proto doporuÄuji se zaregistrovat na <a href="https://platform.openai.com/playground">playgroundu</a>, jakÃ©msi testovacÃ­m webu pro rÅ¯znÃ© modely, kde je moÅ¾nÃ© si s nimi hrÃ¡t, neÅ¾ je zaÄnete pouÅ¾Ã­vat pÅ™es API.</p>
      <p id="3ef4a2e5-4ec8-4ebe-8753-37cef9e4ec58" class="">Do Å¾Ã¡dosti o pÅ™Ã­stup staÄÃ­ napsat nÄ›co jako Å¾e jste developer a Å¾e si to chcete osahat. MusÃ­te to slinkovat s kreditkou a poÄÃ­tejte s tÃ­m Å¾e se za pouÅ¾itÃ­ <a href="https://openai.com/pricing">platÃ­</a>, ale vesmÄ›s dost mÃ¡lo (tÃ½dnÄ› jsem utratil tÅ™eba dva dolary).</p>
      <h2 id="b74caaf5-64e0-44fe-bc35-2db187a731a1" class="">Sparks of Artificial General Intelligence</h2>
      <p id="a2da6ce8-48b1-4285-a8fb-3456dab6cf6d" class="">VyÅ¡lo <a href="https://arxiv.org/pdf/2303.12712.pdf">Sparks of Artificial General Intelligence: Early experiments with GPT-4</a>. A to ukÃ¡zalo, Å¾e se zmÄ›nilo vÅ¡echno, jen si vÄ›tÅ¡ina z nÃ¡s jeÅ¡tÄ› nevÅ¡imla.</p>
      <p id="189bc4e0-c2f9-4236-9b59-8109754230f8" class="">Tady jsou nÄ›jakÃ© drobty z toho vysosanÃ© jako video:</p>
      <figure id="677d7171-164b-4345-ac9e-0907140ffdd2">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/Mqg3aTGNxZ0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <p id="866a0086-2001-497f-95e9-a6fda161a9a9" class="">Nebo tady jako delÅ¡Ã­ talk:</p>
      <figure id="ac3ca78d-8578-434d-8634-8c696524d8c4">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/qbIk7-JPB2c" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <p id="2bb2c6bb-fdef-40a1-b09d-be4757d4fbe2" class="">Ale obecnÄ› doporuÄuji si pÅ™eÄÃ­st to PDF, Äte se to jak sci-fi. Mohl bych se snaÅ¾it to asi nÄ›jak vÃ­c vychvÃ¡lit a vnutit, ale meh. StojÃ­ to za to.</p>
      <h2 id="c6af8207-eb37-44ab-ba6a-91775856eb01" class="">Use cases pro inspiraci (lidi se ptali)</h2>
      <p id="266189ba-45bf-40db-878a-89461f025e06" class="">Tak nÄ›jak vÅ¡echno. Beru to prostÄ› jako <em>â€œintelektuÃ¡lnÃ­ motorâ€</em>, do kterÃ©ho se dÃ¡ nahÃ¡zet co chcete a ono to vÄ›tÅ¡inou nÄ›jak udÄ›lÃ¡, typicky lÃ­p neÅ¾ random kontraktor na mikro trÅ¾iÅ¡tÃ­ch. Ale kdybych mÄ›l nÄ›co vybrat:</p>
      <ol type="1" id="ea948c2d-751f-44bb-ba01-4dbd96422077" class="numbered-list" start="1">
        <li>NÃ¡povÄ›da a plnÄ›nÃ­ konkrÃ©tnÃ­ch vÄ›cÃ­ k PyQt. VÄ›tÅ¡inou vÃ­m co chci, nemÅ¯Å¾u si vzpomenout na jmÃ©no konkrÃ©tnÃ­ metody, nebo objektu, nebo co importovat. Tak to napÃ­Å¡u GPT4 a ono mi vrÃ¡tÃ­ widget, nebo nÄ›jakou operaci. IdeÃ¡lnÃ­ pouÅ¾itÃ­, protoÅ¾e to mÅ¯Å¾u jednoduÅ¡e kontrolovat. VÃ½hoda je Å¾e to Äasto zasadÃ­ i do kontextu, kdyÅ¾ tam pastnu tÅ™eba jmÃ©na existujÃ­cÃ­ch promÄ›nnÃ½ch.</li>
      </ol>
      <ol type="1" id="a88a5925-698a-4421-858a-637be7393efa" class="numbered-list" start="2">
        <li>To samÃ© s boto3. DÄ›lÃ¡m v prÃ¡ci dost Äasto s AWS v pythonu a obÄas si nemÅ¯Å¾u vzpomenout na parametry DynamoDB query, nebo jestli se nÄ›kde pouÅ¾Ã­vÃ¡ client, nebo resource a tak podobnÄ›. Super hlavnÄ› na ty sloÅ¾itÄ›jÅ¡Ã­ vÄ›ci <em>â€œdej mi klienta co se pÅ™ipojÃ­ nÄ›kam a bude filtrovat resources podle properties timestamp tohohle objektu a ..â€</em>. BÄ›hem minuty to vyÅ™eÅ¡Ã­ nÄ›co na Äem jsem typicky strÃ¡vil tÅ™eba pÅ¯l hodiny hledÃ¡nÃ­m a zkouÅ¡enÃ­m. Å½Ã¡dnÃ½ sloÅ¾itÃ½ kÃ³d, spÃ­Å¡ nudnÃ½ boilerplate specifik rÅ¯znÃ½ch knihoven.</li>
      </ol>
      <ol type="1" id="1008a468-580e-4c36-a965-da58bdf5087b" class="numbered-list" start="3">
        <li>ProchÃ¡zecÃ­ galerie v ÄistÃ©m JS na blogu. Byl jsem lÃ­nÃ½ to programovat ruÄnÄ› (a nejsem nadÅ¡enÃ½ z JS), tak jsem prostÄ› vzal existujÃ­cÃ­ javascript, kterÃ½ galerii neÅ™eÅ¡il vÅ¯bec, Å™ekl GPT4 co chci. StaÄilo chvÃ­li s nÃ­m konverzovat ohlednÄ› toho co se mi na jeho Å™eÅ¡enÃ­ nelÃ­bÃ­, jako Å¾e chci vÄ›tÅ¡Ã­ tlaÄÃ­tka vpÅ™ed a vzad, a pak z toho byl funkÄnÃ­ kÃ³d. Taky mÃ¡m v plÃ¡nu ho nechat pÅ™epsat nÄ›jakÃ© specifika CSS u mÄ› na blogu, ze kterÃ½ch mÃ¡m chuÅ¥ se zabÃ­t. Typicky Å¡kÃ¡lovÃ¡nÃ­ na rÅ¯znÃ½ch DPI a podpora mobilnÃ­ch devices.</li>
      </ol>
      <ol type="1" id="eee4f724-a035-4035-a3de-d1c036cd5445" class="numbered-list" start="4">
        <li>PsanÃ­ ORM v rÅ¯znÃ½ch frameworcÃ­ch. Typicky se tÃ­m moc nenamÃ¡hÃ¡m, prostÄ› Å™eknu co chci, v jakÃ©m frameworku a ono to rÅ¯znÃ© dotazy a inserty a podobnÃ© vÄ›ci vymyslÃ­ z 98% za mÄ›. Modely si zatÃ­m pÃ­Å¡u sÃ¡m.</li>
      </ol>
      <ol type="1" id="906de22e-4848-4f1c-98b3-74af0375828e" class="numbered-list" start="5">
        <li>PsanÃ­ HTML parserÅ¯. To mÄ› vÅ¾dycky nebavÃ­, tak jsem prostÄ› vzal kostru objektu s datama co chci (holÃ¡ dataclass v pythonu), zkopÃ­roval README z mÃ©ho parseru, vybral kus HTML a Å™ekl GPT aÅ¥ to doprogramuje. A on to doprogramoval. Tohle skvÄ›le Å¡etÅ™Ã­ Äas.</li>
      </ol>
      <ol type="1" id="669f7914-83ca-4e97-a63d-828ef35637b6" class="numbered-list" start="6">
        <li>VyrÃ¡bÄ›nÃ­ JQ dotazÅ¯ na zÃ¡kladÄ› examplÅ¯ JSONu. ProstÄ› copypaste kusu JSONu, <em>â€œdej mi jq command co z toho vytÃ¡hne vÅ¡echny Xâ€</em>. VrÃ¡til dlouhÃ½ JQ command, kterÃ½ funguje.</li>
      </ol>
      <ol type="1" id="2bd9a38b-1aab-4612-a6d4-90fd56bdab73" class="numbered-list" start="7">
        <li>GenerovÃ¡nÃ­ plantuml a dalÅ¡Ã­ch podobnÃ½ch vÄ›cÃ­, kdy to nÄ›jakou kostru nastÅ™elÃ­ na zÃ¡kladÄ› nÄ›jakÃ©ho slovnÃ­ho popisu a jÃ¡ pak jen doplnÃ­m zbÃ½vajÃ­cÃ­ch 10%. Asi by tÃ­m Å¡lo generovat tÅ™eba README na zÃ¡kladÄ› krÃ¡tkÃ©ho snippetu parsovÃ¡nÃ­ parametrÅ¯ a pÃ¡r textovÃ½ch zmÃ­nek o detailech jako jak pustit testy (â€œje to v pytestuâ€) a tak podobnÄ›.</li>
      </ol>
      <ol type="1" id="8d6f739b-97e6-49e7-b0a5-08c9fd45eaf8" class="numbered-list" start="8">
        <li>GenerovÃ¡nÃ­ Dockerfiles a Docker compose vÄ›cÃ­. HroznÃ½ oser to psÃ¡t ruÄnÄ›.</li>
      </ol>
      <ol type="1" id="fc67d030-ce21-4748-b009-09303135690b" class="numbered-list" start="9">
        <li>DebugovÃ¡nÃ­. Typicky tÅ™eba helm/kubernetes. NÄ›kde se zaseknu, nemÅ¯Å¾u nic vygooglit. KdyÅ¾ chybovou hlÃ¡Å¡ku copypastnu GPT4, tak bÄ›hem pÃ¡r zprÃ¡v vyÅ™eÅ¡Ã­ nÄ›co na Äem jsem byl zaseklÃ½ hodiny (z nedÃ¡vnÃ© doby tÅ™eba detaily ohlednÄ› anotacÃ­ kubernetu, route53, ssl certifikÃ¡tÅ¯, values, overrides a podobnÃ© lahÅ¯dky, nebo kdyÅ¾ se podÄ›lal EFS driver). Jako <em>â€œodsekÃ¡vaÄâ€</em> co vÃ¡s <em>odsekne</em> ze <em>zÃ¡seku</em> (ÄeÅ¡tina &lt;3), je GPT naprosto geniÃ¡lnÃ­ a ÄlovÄ›k mÃ­sto aby na nÄ›Äem zabÃ­jel Äas, tak se posunuje ÃºÅ¾asnÄ› rychle dÃ¡l.</li>
      </ol>
      <ol type="1" id="f753787e-6190-4f39-9e01-0e43f9b0ef79" class="numbered-list" start="10">
        <li>Do budoucna chci asi nÄ›jak nascriptovat pÅ™eklad blogu do rÅ¯znÃ½ch dalÅ¡Ã­ch jazykÅ¯. Jazyky pÅ™estaly bÃ½t podstatnÃ©, tak proÄ to nepÅ™eloÅ¾it do vÄ›tÅ¡iny hlavnÃ­ch automaticky a za pÃ¡r dolarÅ¯? UÅ¾ teÄ to mÃ¡ lepÅ¡Ã­ kvalitu neÅ¾ levnÃ­ lidÅ¡tÃ­ pÅ™ekladatelÃ© (150kÄ/normostrana) z rÅ¯znÃ½ch trÅ¾iÅ¡Å¥ a cena bude v Å™Ã¡du centÅ¯ za ÄlÃ¡nek.</li>
      </ol>
      <p id="dc84c1d4-48e7-4a71-8173-59c7539b2221" class="">SamozÅ™ejmÄ› je tÅ™eba Å™Ã­ct dvÄ› vÄ›ci:</p>
      <ol type="1" id="b79a7350-013c-4ea7-8961-d7ff250c7ad2" class="numbered-list" start="1">
        <li>MomentÃ¡lnÄ› tam neposÃ­lÃ¡m osobnÃ­, nebo firemnÃ­ data. VÅ¾dycky nÄ›co popÃ­Å¡u a nechÃ¡m si nÄ›co vygenerovat. ObecnÄ› nic citlivÃ©ho asi na internet posÃ­lat nechcete a tady to platÃ­ taky. BÅ¯h vÃ­ co s tÃ­m za 10 let bude nÄ›jakÃ¡ dalÅ¡Ã­ verze AI dÄ›lat.</li>
      </ol>
      <ol type="1" id="bf91d4fa-4a54-4cf0-90d2-1a0c3ea13a3d" class="numbered-list" start="2">
        <li>Nikdy niÄemu z toho z podstaty nevÄ›Å™Ã­m. Je to Shoggoth s kÃ½m se bavÃ­m, ne kolega. CoÅ¾ ovÅ¡em neznamenÃ¡, Å¾e to nenÃ­ uÅ¾iteÄnÃ©, jen od toho neÄekejte zÃ¡zraky a vÅ¡echno ovÄ›Å™ujte.</li>
      </ol>
      <h3 id="7c1c9116-9584-4179-853e-29a781ebf56f" class="">NÄ›jakÃ© plÃ¡ny do budoucna</h3>
      <p id="0dd6d63b-d5b5-4f85-9939-d7a17c3b02bb" class="">VyzkouÅ¡et trÃ©ning menÅ¡Ã­ch modelÅ¯ na vlastnÃ­ch datasetech. Asi formou EC2 v AWS, neÅ¾ kupovÃ¡nÃ­m novÃ© grafiky za 50k, ale uvidÃ­me. VesmÄ›s vÅ¡echny konzumnÃ­ grafiky majÃ­ poÅ™Ã¡d mÃ¡lo VRAM.</p>
      <p id="754acebb-d39a-4e7d-845b-d044efa2b114" class="">VyzkouÅ¡et vytvoÅ™it vlastnÃ­ embedingy a vektorovÃ© databÃ¡ze a jak moc dobÅ™e to funguje na vyhledÃ¡vÃ¡nÃ­ skrz OpenAI. Lidi to pouÅ¾Ã­vajÃ­, jde mi o to zjistit jakou to mÃ¡ uÅ¾iteÄnost a moÅ¾nÃ¡ to vztÃ¡hnout na vÅ¡echno co mÃ¡m v PC.</p>
      <p id="9af91f20-ca22-445e-829f-8ab662292b50" class="">Zkusit nÄ›jak vecpat GPT4 rÅ¯znÃ© nÃ¡stroje, integrovat do rÅ¯znÃ½ch vÄ›cÃ­ API a tÃ­m zlepÅ¡it jeho uÅ¾iteÄnost. Nejde mi o uÅ¾iteÄnost modelu - ta je fantastickÃ¡ uÅ¾ teÄ, jen mÄ› nebavÃ­ poÅ™Ã¡d dokola psÃ¡t ty samÃ© prompty, nebo tam/zpÄ›t nÄ›jak kostrbatÄ› kopÃ­rovat rÅ¯znÃ© kusy kÃ³du. IdeÃ¡lnÄ› to nÄ›jak lÃ­p integrovat do systÃ©mu (kliknu pravÃ½m, vyberu konverzace s GPT, otevÅ™e se mi moje custom gui kde Å™eÅ¡Ã­m ty data s chatbotem).</p>
      <h2 id="e0bd251d-faca-4bfc-9471-75287885d946" class="">Trendy a budoucnost</h2>
      <p id="ad535e6a-9647-48d1-9174-bdc30e7d24d9" class="">OÄividnÃ© jsou samozÅ™ejmÄ› vÄ›tÅ¡Ã­ modely, ale spÃ­Å¡ taky modely s vÄ›tÅ¡Ã­m kontextovÃ½m oknem. OsobnÄ› jsem si zatÃ­m jeÅ¡tÄ› nenaÄetl co to vlastnÄ› limituje, ale tÄ›ch 8k kontextu (jak moc tokenÅ¯ je ten model schopnÃ½ vnÃ­mat) v GPT4 dÄ›lÃ¡ brutÃ¡lnÃ­ rozdÃ­l oproti 1/2k GPT3. A to majÃ­ i 32k verzi, jen mÃ¡ pomalejÅ¡Ã­ uvedenÃ­ mezi lidi.</p>
      <p id="e3290b4e-5245-4217-8296-12327722978c" class="">V roce 2020 jsem v ÄlÃ¡nku <a href="../../Predstaveni/GPT-3.html" title="GPT-3">GPT-3</a> psal:</p>
      <blockquote id="05b7b670-54bc-4f77-98cb-b0f6241058fb" class="">
        MyslÃ­m Å¾e se zpÅ™Ã­stupnÄ›nÃ­m API se otevÅ™e novÃ¡ pozice â€kormidelnÃ­kaâ€œ vÃ½stupu, tedy druh specializace lidÃ­, jenÅ¾ budou nabÃ­zet generovÃ¡nÃ­ â€pÅ™edpÅ™ipravenÃ­â€œ a nastavenÃ­ parametrÅ¯ pro Å™eÅ¡enÃ­ konkrÃ©tnÃ­ch problÃ©mÅ¯.
      </blockquote>
      <p id="3438bcfe-6a4a-438f-8bf4-88c6bfc0119c" class="">Tak uÅ¾ to existuje jako pracovnÃ­ pozice a Å™Ã­kÃ¡ se tomu <em>â€œprompt engineeringâ€</em>. Cool. Co jsem tak vidÄ›l, tak se rozjÃ­Å¾dÃ­ docela business ohlednÄ› implementace AI do vÅ¡eho moÅ¾nÃ©ho. ÄŒasto dost vaporware, ale tÅ™eba ve vyhledÃ¡vÃ¡nÃ­ pÅ™es ty <em>embeddingy</em> to pÅ¯sobilo dost hustÄ›.</p>
      <p id="3b826d74-78f2-4216-9989-8d09fac6b474" class="">MomentÃ¡lnÄ› asi nejvÄ›tÅ¡Ã­ problÃ©m vÅ¡ech modelÅ¯ je jejich izolovanost, omezenÃ½ kontext a neschopnost se uÄit. TakÅ¾e do budoucna:</p>
      <ol type="1" id="a2963632-8df5-438f-97fe-a94c1bd3a9e9" class="numbered-list" start="1">
        <li>Nebudou izolovanÃ© - budou mÃ­t pÅ™Ã­stup k nÃ¡strojÅ¯m a napÅ™Ã­klad bude jednoduchÃ© do nich nacpat svoje data. Tohle vnÃ­mÃ¡m jako velkou bolest, ideÃ¡lnÄ› bych to chtÄ›l mÃ­t lokÃ¡lnÄ› bÄ›Å¾Ã­cÃ­ a napÅ™Ã­Ä vÅ¡Ã­m. <em>â€œNajdi mi odkaz co vÄera posÃ­lal kamarÃ¡d na IRCâ€</em>. <em>â€œPÅ™ed pÃ¡r lety jsem napsal script co vypisuje strukturu HTML webÅ¯, najdi ho mezi stovkama dalÅ¡Ã­châ€</em>. <em>â€œTu akci co jsem teÄ udÄ›lal, napiÅ¡ na nÃ­ script a pÅ™iÅ™aÄ klÃ¡vesovou zkratkuâ€</em>. <em>â€œTy data co teÄ vidÃ­m na monitoru, udÄ›lej s nima tohle a tohleâ€</em>. Siri a Alexa, co nenÃ­ ÃºplnÄ› dementnÃ­ a k niÄemu. â€œNÃ¡strojeâ€ (integrace s rÅ¯znÃ½mi API) uÅ¾ jsou v betaverzi a prÃ½ to funguje skvÄ›le.</li>
      </ol>
      <ol type="1" id="e9a3ca52-8ccb-493c-8502-d834a51cb235" class="numbered-list" start="2">
        <li>Budou mÃ­t ÄÃ­m dal vÄ›tÅ¡Ã­ kontext. Jednou se budeme tÄ›m 32k kontextu smÃ¡t a nechÃ¡pat, stejnÄ› jako si neumÃ­me pÅ™edstavit fungovat dneska na osmibitu s 32k RAM.</li>
      </ol>
      <ol type="1" id="a1e6860c-2434-499d-a6d0-954cd1928381" class="numbered-list" start="3">
        <li>Modely se samozÅ™ejmÄ› budou uÄit, a budou mÃ­t rÅ¯znÃ© formy dlouhodobÃ© pamÄ›ti, aÅ¥ uÅ¾ pÅ™euÄenÃ­, nebo vÄ›ci jako <a href="https://www.pinecone.io/">pinecone</a> a dalÅ¡Ã­ odkladaÄe embedingÅ¯. Taky budou mÃ­t integrovanou reflexi, tedy schopnost nÄ›jak vidÄ›t do vlastnÃ­ho uvaÅ¾ovÃ¡nÃ­ a napÅ™Ã­klad vyloÅ¾it tokenizaci, jak jsou uloÅ¾eny data a tak podobnÄ›. Tohle dneska jde zjistit, ale je to brutÃ¡lnÄ› sloÅ¾itÃ© a kostrbatÃ©.
        </li>
      </ol>
      <p id="882cfca8-da6a-40db-8f4b-501397c6a57e" class="">PostupnÄ› budou schopny dÄ›lat ÃºplnÄ› vÅ¡echno. To uÅ¾ jsou vesmÄ›s teÄ, akorÃ¡t je to v plenkÃ¡ch, alignment obÄas nefunguje a sem tam stojÃ­ vÃ­c nÃ¡mahy to modelu vysvÄ›tlit, neÅ¾ to udÄ›lat ruÄnÄ›. Ale zlepÅ¡uje se to skokama na ÃºroveÅˆ, kterÃ¡ mÄ› stÃ¡le pÅ™ekvapuje, pÅ™estoÅ¾e jsem docela informovanÃ½.</p>
      <h2 id="6ee05db9-ff9b-43e0-a59f-24bf64683e43" class="">AGI</h2>
      <p id="507303b8-4ab4-410a-b10d-3f42c31001ca" class="">A blÃ­Å¾Ã­ se konec. Ne lidstva, ale blogu. TakÅ¾e k AGI:</p>
      <p id="5298ea4e-80a4-45d2-9246-1166d7415a13" class="">Podle mÃ©ho nÃ¡zoru tohle pÅ™Ã­mo povede k AGI, tedy Artificial General Intelligence, AI kterÃ¡ je v prÅ¯mÄ›ru schopnÃ¡ <em>vÅ¡eho</em> intelektuÃ¡lnÃ­ho stejnÄ› dobÅ™e, nebo lÃ­p neÅ¾ <em>ÄlovÄ›k</em> (coÅ¾ neznamenÃ¡ Å¾e bude <em>poÅ™Ã¡d</em> dÄ›lat <em>vÅ¡echno</em> lÃ­p neÅ¾ <em>vÅ¡ichni</em> ostatnÃ­).</p>
      <p id="96e3646e-54d6-477c-98c6-37b3f456e1c4" class="">Ne Å¾e by to bylo ÃºplnÄ› na dohled, ale teÄ je to jen otÃ¡zka vyzkouÅ¡enÃ­ rÅ¯znÃ½ch pÅ™Ã­stupÅ¯, zlepÅ¡enÃ­ Å¡kÃ¡lovÃ¡nÃ­ a tak podobnÄ›. Po sto letech kdy nikdo nemÄ›l vÅ¯bec Å¾Ã¡dnÃ© tuÅ¡enÃ­ co jak na to, a vÄ›dci se ani nedokÃ¡zali shodnout na pojmu â€œinteligenceâ€, je tohle koneÄnÄ› tady. Jen je to zatÃ­m stÃ¡le ponÄ›kud hloupÃ©.</p>
      <p id="39ec2e92-2004-4167-900a-085920fec82c" class="">Tohle je jako prvnÃ­ letadlo. LetÃ­ to, hurÃ¡. Ale hlavnÄ› to ukazuje <em>cestu</em>, a Å¾e <em>je to moÅ¾nÃ©</em>, a nejspÃ­Å¡ i <em>jak</em>. TeÄ jde jen o na tom chvÃ­li dÄ›lat, starÃ½m dobrÃ½m iterativnÃ­m vÃ½vojem.</p>
      <p id="88788a43-2b77-4db4-9349-e30fd6e501ce" class="">Co mÄ› velmi zaujalo jsou jakÃ©si <a href="https://en.wikipedia.org/wiki/Strange_loop">strangeloopy</a>, kterÃ© lidi s GPT poslednÃ­ dobou dÄ›lajÃ­. KrÃ¡snÃ½m pÅ™Ã­kladem je tÅ™eba <a href="https://github.com/Torantulino/Auto-GPT">Auto-GPT: An Autonomous GPT-4 Experiment</a>. CoÅ¾ v podstatÄ› vezme vÃ¡Å¡ request, model se prvnÄ› zamyslÃ­ jak ho udÄ›lat, a pak pomocÃ­ rÅ¯znÃ½ch nÃ¡strojÅ¯ interaguje s webem a diskem a tak podobnÄ›, a kdyÅ¾ je nÄ›co moc velkÃ© (pÅ™esahuje to kontextovÃ© okno), tak na to spouÅ¡tÃ­ dalÅ¡Ã­ modely, kterÃ© instruuje. BÄ›hem toho si rÅ¯znÄ› uklÃ¡dÃ¡ informace na disk, kterÃ© si pak Äte zpÃ¡tky, aby instruoval sÃ¡m sebe. Teoreticky je to schopnÃ© plnit docela vysokoÃºrovÅˆovÃ© cÃ­le, v praxi je to zatÃ­m poÅ™Ã¡d v plenkÃ¡ch a dost Äasto se to nÄ›kde ztratÃ­.</p>
      <p id="12d64658-d414-4e8d-a5e6-2a787c5ea928" class="">MomentÃ¡lnÄ› je to tedy dost nepouÅ¾itelnÃ©, ale celkovÄ› to zaÄÃ­nÃ¡ docela dobÅ™e simulovat sloÅ¾itÄ›jÅ¡Ã­ myÅ¡lenkovÃ© procesy. Dost mi to pÅ™ipomÄ›lo mÅ¯j starÃ½ blogpost <a href="../../Crypto/Entity.html" title="Entity">Entity</a>, kde jsem popisoval systÃ©m, co nenÃ­ inteligentnÃ­, ale pronajÃ­mÃ¡ si na vylepÅ¡ovÃ¡nÃ­ sebe sama inteligenci od lidÃ­. A tohle v podstatÄ› dokÃ¡Å¾e podobnÄ› delegovat inteligenci, akorÃ¡t samo na sebe.</p>
      <h1 id="6f65d856-a508-4cb1-884b-20a88506b318" class="">OdkazovnÃ­k</h1>
      <ul id="98f95bf5-2f13-4c3f-a025-155de42ab388" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient Foundation Language Models</a>
        </li>
      </ul>
      <ul id="9f2b9b68-27f4-4864-9593-7b5deac52a55" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca: A Strong, Replicable Instruction-Following Model</a>
        </li>
      </ul>
      <ul id="987571ef-d8b4-4b77-9738-13629a3d4db6" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://astralcodexten.substack.com/p/janus-simulators">Janus' Simulators</a>
        </li>
      </ul>
      <ul id="4a504626-5dad-4cfa-bee8-93896cdeb2d3" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://github.com/pointnetwork/point-alpaca">point-alpaca</a>
        </li>
      </ul>
      <ul id="25b6d604-a819-4702-9237-d1d26d5fce23" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://huggingface.co/blog/rlhf">Illustrating Reinforcement Learning from Human Feedback (RLHF)</a>
        </li>
      </ul>
      <ul id="174deb01-11f2-4f69-a418-2ad4b5c7b4ad" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://arxiv.org/pdf/2212.10560.pdf">SELF-INSTRUCT: Aligning Language Model with Self Generated Instructions</a>
        </li>
      </ul>
      <ul id="31e9fc03-17c9-41fb-83ef-cf9cfc90c803" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://arxiv.org/pdf/2106.09685.pdf">LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</a>
        </li>
      </ul>
      <ul id="91995b01-1f11-426c-9021-838a7fd267ed" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://huggingface.co/blog/stackllama">StackLLaMA: A hands-on guide to train LLaMA with RLHF</a>
        </li>
      </ul>
      <ul id="ec2d7402-a50b-4578-85bc-bf3852854ef3" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://arxiv.org/pdf/2303.11366.pdf">Reflexion: an autonomous agent with dynamic memory and self-reflection</a>
        </li>
      </ul>
      <ul id="34197024-eff1-4eef-b1d1-3301127d674d" class="bulleted-list">
        <li style="list-style-type:disc">
          <a href="https://arxiv.org/abs/2304.03442">Generative Agents: Interactive Simulacra of Human Behavior</a>
        </li>
      </ul>
      <h3 id="76e1bffc-0708-453f-9115-be8490782e41" class="">Random poznÃ¡mky</h3>
      <p id="86edcfb9-127f-4060-96bb-ff11cd4537a4" class="">V twitter infosfÃ©Å™e chcete sledovat <a href="https://twitter.com/Plinz">Joshu Bacha</a>. A <a href="https://twitter.com/JCorvinusVR">JCorvinus</a> taky docela jede.</p>
      <p id="b37ab524-7168-4467-a5c1-81a9dfb5e7ec" class="">Tohle stojÃ­ za shlÃ©dnutÃ­:</p>
      <figure id="9a215463-48c2-43ac-bb75-9216b95326b9">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/L_Guz73e6fw" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <figure id="38919c51-41fa-4bec-ab26-3a6d79954048">
        <div class="source">
          <iframe width="100%" height="50%" frameborder="0" src="https://www.youtube.com/embed/goOa0biX6Tc" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </figure>
      <p id="30b0fe9b-a3fd-4745-b311-018c41fd523e" class="">NekoneÄnÃ© diskuze o morÃ¡lce a copyrightu a inteligenci a zneuÅ¾itelnosti a tak podobnÄ› jsou podle mÃ©ho nÃ¡zoru jalovÃ½ <a href="https://www.definitions.net/definition/bikeshedding">bikeshedding</a>. Lidi to poÅ™Ã¡d Å™eÅ¡Ã­, protoÅ¾e to mÅ¯Å¾e Å™eÅ¡it kaÅ¾dÃ½, ale na vÃ½sledku debaty naprosto nezÃ¡leÅ¾Ã­. NeplÃ½tvat na tom Äas.</p>
      <p id="3cad6498-a8e6-4e30-92bb-5faa254e271c" class="">Depresi z toho Å¾e AI bude umÄ›t vÅ¡echno lÃ­p neÅ¾ vy asi netÅ™eba, uÅ¾ teÄ existuje na svÄ›tÄ› nÄ›kdo, kdo asi umÃ­ cokoliv z toho co umÃ­te lÃ­p neÅ¾ vy. Pokud berete motivaci jen z tohohle, tak si prostÄ› najdÄ›te jinou motivaci. TÅ™eba se zamyslete jak vÃ¡m to umoÅ¾nÃ­ zlepÅ¡it svÅ¯j potenciÃ¡l dosahovat cÃ­lÅ¯ kterÃ© fakt chcete.</p>
    </div>
  </article>
  <div class="corner-ribbon top-right red">
    <a href="https://www.patreon.com/bePatron?u=2618881">Become a Patron</a>
  </div><a class="twitter-share-button" id="twitter_button" href="#"><img src="../../../tweet_button.svg"></a>
  <div id="sidebar_bottom">
    <hr>
    <p>Did you enjoy the blogpost? Here are other posts from this blog:</p>
    <div id="last_five_bottom">
      <ul>
        <li>
          <a href="../Jak_na_vlastni_LLM_GPT.html" title="Jak na vlastnÃ­ LLM (GPT)">Jak na vlastnÃ­ LLM (GPT)</a>
        </li>
        <li>
          <a href="../../Povidky/Software.html" title="Software">Software</a>
        </li>
        <li>
          <a href="../../Ostatni/Paromobilita_je_budoucnost.html" title="Paromobilita je budoucnost">Paromobilita je budoucnost</a>
        </li>
        <li>
          <a href="../../Ostatni/Algoritmus_hledani_programatorske_prace_2021-4.html" title="Algoritmus hledÃ¡nÃ­ programÃ¡torskÃ© prÃ¡ce 2021/4">Algoritmus hledÃ¡nÃ­ programÃ¡torskÃ© prÃ¡ce 2021/4</a>
        </li>
        <li>
          <a href="../../3D_tisk/Nastaveni_Blenderu_pro_3D_tisk.html" title="NastavenÃ­ Blenderu pro 3D tisk">NastavenÃ­ Blenderu pro 3D tisk</a>
        </li>
        <li>
          <a href="../../3D_modelovani/Geometricky_stred_Prahy.html" title="GeometrickÃ½ stÅ™ed Prahy">GeometrickÃ½ stÅ™ed Prahy</a>
        </li>
        <li>
          <a href="../../../Utrzky/Posta_poezie.html" title="PoÅ¡ta (poezie)">PoÅ¡ta (poezie)</a>
        </li>
        <li>
          <a href="../../Ostatni/Statni_zklamani.html" title="StÃ¡tnÃ­ zklamÃ¡nÃ­">StÃ¡tnÃ­ zklamÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../3D_tisk/3D_TODO_list_1_Drzak_na_sluchatka.html" title="3D TODO list 1; DrÅ¾Ã¡k na sluchÃ¡tka">3D TODO list 1; DrÅ¾Ã¡k na sluchÃ¡tka</a>
        </li>
        <li>
          <a href="../../Ostatni/Dva_podvodnici.html" title="Dva podvodnÃ­ci">Dva podvodnÃ­ci</a>
        </li>
      </ul>
    </div>
    <p>You can find <a href="../../../Zmeny.html" title="ZmÄ›ny">many more in changelog</a>..</p>
    <div>
      <h3>Tagy</h3>
      <p><a href="../../../Tagy/ai.html" title="ai">ai</a>, <a href="../../../Tagy/dao.html" title="dao">dao</a>, <a href="../../../Tagy/gpt.html" title="gpt">gpt</a></p>
    </div>
    <div>
      <h3>Blog categories</h3>
      <ul class="no_icon">
        <li>
          <a href="../../3D_modelovani.html" title="3D modelovÃ¡nÃ­">ğŸ“‚ 3D modelovÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../3D_tisk.html" title="3D tisk">ğŸ“‚ 3D tisk</a>
        </li>
        <li>
          <a href="../../Abclinuxu.html" title="Abclinuxu">ğŸ“‚ Abclinuxu</a>
        </li>
        <li>
          <a href="../../Crypto.html" title="Crypto">ğŸ“‚ Crypto</a>
        </li>
        <li>
          <a href="../../Hardware.html" title="Hardware">ğŸ“‚ Hardware</a>
        </li>
        <li>
          <a href="../../Hrbitov.html" title="HÅ™bitov">ğŸ“‚ HÅ™bitov</a>
        </li>
        <li>
          <a href="../../Knihy.html" title="Knihy">ğŸ“‚ Knihy</a>
        </li>
        <li>
          <a href="../../Ostatni.html" title="OstatnÃ­">ğŸ“‚ OstatnÃ­</a>
        </li>
        <li>
          <a href="../../Povidky.html" title="PovÃ­dky">ğŸ“‚ PovÃ­dky</a>
        </li>
        <li>
          <a href="../../Predstaveni.html" title="PÅ™edstavenÃ­">ğŸ“‚ PÅ™edstavenÃ­</a>
        </li>
        <li>
          <a href="../../Programovani.html" title="ProgramovÃ¡nÃ­">ğŸ“‚ ProgramovÃ¡nÃ­</a>
        </li>
        <li>
          <a href="../../index.html" title="Czech section">ğŸ“‚ Czech section</a>
        </li>
      </ul>
    </div>
    <h3>Follow this blog</h3>
    <div>
      <a href="https://blog.rfox.eu/atom_cz.xml"><img src="../../../rss_icon.png" style="width: 5em;"></a>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;<a href="https://twitter.com/Bystroushaak"><img src="../../../twitter_icon.png" style="width: 5em;"></a>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;<a href="https://www.patreon.com/bePatron?u=2618881"><img src="../../../patreon.png" style="width: 5em;"></a>
    </div>
  </div>
</body>
</html>
